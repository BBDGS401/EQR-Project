---
title: "Study EQR Data"
author: "Cheeson Lau"
date: "2024-07-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)

setwd("O:/POOL/PRIVATE/RISKMGMT/EQR Reporting/EQR Study")
```

# Introduction

This document intends to explore 10 year trend of energy product in trading hubs. It also dives into ancillary products pricing in the second half. Some potential trends I will examine include quantity transacted and price patterns, compared to ICE daily index, weather condition, hydro condition, gas prices, etc. There will also be a correlation study between SCL trading activities/net position and trade hub trend. I will try to identify similar days in history for energy trading and predict index prices at trading hubs if possible.

I am using EQR data files for all companies from FERC website from 2014 Q1 - 2024 Q1 in this study. I divided the data into 4 datasets: energy product daily, energy product hourly, ancillary product daily, ancillary product hourly. All datasets are pre-processed using python. They are all almost ready to be used. I will start with studying energy datasets first, and ancillary datasets second. The definition of columns are at the end of the document. Please note that companies may file transactions according to their own understanding of the EQR filing requirements guide, and it is almost certain that they don't a uniform interpretation of it. Therefore, the data is almost guaranteed to not reflect EIM faultlessly.

# Energy -- Daily
## Dataset

```{r}
import_energy_daily <- function() {
  
  # I used fread() because it is faster than read.csv() and read_csv()
  energy_daily_data <- data.table::fread("Final_Data_Files/final_energy_transactions_daily.csv")
  
  print(nrow(energy_daily_data))
  
  # Convert datatype of transaction_begin_date, transaction_end_date, and trade_date to POSIXct or date from char or int
  energy_daily_data[, transaction_begin_date := as.POSIXct(transaction_begin_date, format="%Y/%m/%d %H:%M")]
  energy_daily_data[, transaction_end_date := as.POSIXct(transaction_end_date, format="%Y/%m/%d %H:%M")]
  energy_daily_data[, trade_date := lubridate::ymd(trade_date)]
  
  # Fixed unmatching cases in the increment_name column
  # H and h should be one group, D and d should be one group, so are M and m
  energy_daily_data[, increment_name := gsub("^d$", "D", increment_name)]
  energy_daily_data[, increment_name := gsub("^h$", "H", increment_name)]
  energy_daily_data[, increment_name := gsub("^m$", "M", increment_name)]
  
  # Fixed unmatching cases in the point_of_delivery_specific_location column
  # There should only be two acceptable hubs: Mid-C and COB
  energy_daily_data <- energy_daily_data %>%
  mutate(point_of_delivery_specific_location = str_to_upper(point_of_delivery_specific_location))
  
  # Now, let's filter out the outliers
  # Definition of outliers: when price is lower than -$20 or higher than $2000
  # These data are likely incorrectly filed by the companies, so I decided to not include them in the study (it could also be due to accidents or extreme weather, but $2000/MWh is enough to cover them)
  energy_daily_data <- energy_daily_data %>% filter(price >= -20 & price <= 2000)
  
  print(nrow(energy_daily_data))
  
  # Also, non-positive transaction_quantity should not exist in the dataset as they are a result of wrong filing by companies. Only selling transactions should be filed in EQR
  energy_daily_data <- energy_daily_data %>% filter(transaction_quantity > 0)
  
  print(nrow(energy_daily_data))
  
  # We also need remove transactions with price = $0/MWh and transaction_quantity > 10000 MWh, these transactions are quite likely a result of incorrect or questionable filling
  # Unlikely that someone sold large amount of free energy in a day
  # Doesn't matter if the filing is actually true, these data will skew the data and mess up plots
  energy_daily_data <- energy_daily_data %>% filter(!(price == 0 & transaction_quantity > 10000))
  
  print(nrow(energy_daily_data))
  
  # We will filter out transaction with transaction_quantity > 50000 MWh
  # There are 7 such transactions
  # All 7 of them are sold by Morgan Stanley to PUD 2 of Grant County
  # All 7 transactions have a one hour duration. The transaction_quantity is too gigantic in such a short period of time
  energy_daily_data <- energy_daily_data %>% filter(transaction_quantity <= 50000)
  
  print(nrow(energy_daily_data))

  # Assign to the global environment
  assign("energy_daily_data", energy_daily_data, pos = .GlobalEnv)
}
```

```{r}
# 5453260 obs
import_energy_daily()
```

Now energy_daily_data is all set. Lets start crunching some descriptive statistics on energy_daily_data.

## Descriptive Statistics

I will provide descriptive statistics of energy_daily_data such as measures of central tendency, measures variability and measures of frequency distribution. Line charts, violin plots, and pie charts are utilized to visualize and assist analysis.

Lets start with finding min, Q1, median (Q2), Q3, max, mean, standard deviation (sd), interquartile range (iqr) of transaction_quantity, price, total_transaction_charge. The unit of price is \$/MWh and unit of quantity is MWh. Note that all the descriptive statistics below are measured per day, so if a transaction has a longer day_duration, it has more impact on the mean of transaction_quantity and total_transaction_charge.

### Subgroups -- type_of_rate

I will breakdown data into subgroups for comparison. Start with grouping by type_of_rate.

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by type_of_rate
unique_transaction_count <- energy_daily_data %>%
  mutate(type_of_rate = tolower(type_of_rate)) %>%
  group_by(type_of_rate) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = tolower(type_of_rate), y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Type of Rate",
    x = "Type of Rate",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

43.6% of transactions have fixed type_of_rate.  
42.8% of transactions have electric index type_of_rate.  
13.3% of transactions have rto/iso type_of_rate.  
Rarest of them all, 0.29% of transactions have formula type_of_rate.

```{r echo = FALSE}
energy_daily_data %>%
  mutate(type_of_rate = tolower(type_of_rate)) %>%
  group_by(type_of_rate) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity),
    q1_transaction_quantity = quantile(transaction_quantity, 0.25),
    median_transaction_quantity = median(transaction_quantity),
    q3_transaction_quantity = quantile(transaction_quantity, 0.75),
    max_transaction_quantity = max(transaction_quantity),
    mean_transaction_quantity = mean(transaction_quantity),
    sd_transaction_quantity = sd(transaction_quantity),
    iqr_transaction_quantity = IQR(transaction_quantity)
  ) %>%
  pivot_longer(
    cols = -type_of_rate,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(type_of_rate, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% 
  filter(transaction_quantity <= 1000)

ggplot(processed_data, aes(x = tolower(type_of_rate), y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Type of Rate",
    x = "Type of Rate",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  mutate(type_of_rate = tolower(type_of_rate)) %>%
  group_by(type_of_rate) %>%
  summarise(
    min_price = min(price),
    q1_price = quantile(price, 0.25),
    median_price = median(price),
    q3_price = quantile(price, 0.75),
    max_price = max(price),
    mean_price = mean(price), 
    sd_price = sd(price),
    iqr_price = IQR(price)
  ) %>%
  pivot_longer(
    cols = -type_of_rate,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(type_of_rate, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(price <= 250)

ggplot(processed_data, aes(x = tolower(type_of_rate), y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Type of Rate",
    x = "Type of Rate",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  mutate(type_of_rate = tolower(type_of_rate)) %>%
  group_by(type_of_rate) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge),
    q1_total_transaction_charge = quantile(total_transaction_charge, 0.25),
    median_total_transaction_charge = median(total_transaction_charge),
    q3_total_transaction_charge = quantile(total_transaction_charge, 0.75),
    max_total_transaction_charge = max(total_transaction_charge),
    mean_total_transaction_charge = mean(total_transaction_charge),
    sd_total_transaction_charge = sd(total_transaction_charge),
    iqr_total_transaction_charge = IQR(total_transaction_charge)
  ) %>%
  pivot_longer(
    cols = -type_of_rate,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(type_of_rate, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(total_transaction_charge <= 25000 & total_transaction_charge >= -1000)

ggplot(processed_data, aes(x = tolower(type_of_rate), y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Type of Rate",
    x = "Type of Rate",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

Note that $\text{total_transaction_charge} = \text{transaction_quantity} \times \text{price}$ since $\text{total_transmission_charge} = 0$.

Also note that a small number of transactions with abnormally high price and/or transaction_quantity and/or total_transaction_charge are not included in the violin plots for better comprehension and aesthetics. They are still considered in the number tables.

Formula type_of_rate has highest mean and median transaction_quantity, price and total_transaction_charge. However, its max transaction_quantity and price ranks the lowest among the four groups. But I cannot assume that most transactions of formula type_of_rate are medium-sized, slightly expensive transactions because iqr is the highest in all three metrics. The violin plots also tell a different story. The distribution of transaction_quantity looks the most uniform among the four groups. The price distribution is clearly bimodal. The two peaks are around \$40/MWh and around \$90/MWh. Transactions with formula type_of_rate are the most diverse.

Type_of_rate rto/iso have the smallest mean and median total transaction charge, due to its significantly smaller transaction_quantity in general. Median price is the second highest among the four groups, while mean price is the second lowest. The violin plots demonstrate that most rto/iso type of rate transactions are small and cheap transactions. Total transaction charge is very concentrated. sd, iqr and violin plot all verify that.

Transactions with type_of_rate electric index do not stand out in any metrics particularly. The only thing that is notable is that the minimum total_transaction_charge is -\$57466.21, but that doesn't tell a lot about the transactions. Its distribution of price looks similar to rto/iso. Most transactions are small and cheap, but the level of variation ranks second among the four groups according to the violin plots.

Fixed type_of_rate transactions also have moderate mean and median total_transaction_charge, a bit lower than electric index. Its sd of total_transaction_charge is also relatively small compared to some other groups. Mean, median, IQR of price are the lowest, and sd is also very low. Therefore I will assume that most fixed type_of_rate transactions are relatively small and cheap (slightly bigger than rto/iso), and there are less variations in the group (slightly less than electric index). Interestingly, there a significantly number of trasnaction with a near-zero price. Total transaction charge has a bimodal distribution (one peak looks close to \$0, another close to \$1000).

### Subgroups -- term_name

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by term_name
unique_transaction_count <- energy_daily_data %>%
  group_by(term_name) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = term_name, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Term Name",
    x = "Term Name",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

Transactions are comprised of 24.4% LT transactions and 75.6% LT transactions.

```{r echo = FALSE}
energy_daily_data %>%
  group_by(term_name) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity),
    q1_transaction_quantity = quantile(transaction_quantity, 0.25),
    median_transaction_quantity = median(transaction_quantity),
    q3_transaction_quantity = quantile(transaction_quantity, 0.75),
    max_transaction_quantity = max(transaction_quantity),
    mean_transaction_quantity = mean(transaction_quantity),
    sd_transaction_quantity = sd(transaction_quantity),
    iqr_transaction_quantity = IQR(transaction_quantity)
  ) %>%
  pivot_longer(
    cols = -term_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(term_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(transaction_quantity <= 1000)

ggplot(processed_data, aes(x = term_name, y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Term Name",
    x = "Term Name",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(term_name) %>%
  summarise(
    min_price = min(price),
    q1_price = quantile(price, 0.25),
    median_price = median(price),
    q3_price = quantile(price, 0.75),
    max_price = max(price),
    mean_price = mean(price), 
    sd_price = sd(price),
    iqr_price = IQR(price)
  ) %>%
  pivot_longer(
    cols = -term_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(term_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(price <= 250)

ggplot(processed_data, aes(x = term_name, y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Term Name",
    x = "Term Name",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(term_name) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge),
    q1_total_transaction_charge = quantile(total_transaction_charge, 0.25),
    median_total_transaction_charge = median(total_transaction_charge),
    q3_total_transaction_charge = quantile(total_transaction_charge, 0.75),
    max_total_transaction_charge = max(total_transaction_charge),
    mean_total_transaction_charge = mean(total_transaction_charge),
    sd_total_transaction_charge = sd(total_transaction_charge),
    iqr_total_transaction_charge = IQR(total_transaction_charge)
  ) %>%
  pivot_longer(
    cols = -term_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(term_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(total_transaction_charge <= 25000 & total_transaction_charge >= -1000)

ggplot(processed_data, aes(x = term_name, y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Term Name",
    x = "Term Name",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

ST transactions have the most extreme min and max prices, which is reasonable due to emergency demand/supply for energy. However, it doesn't mean the price of ST transactions are more diverse. By looking at sd, iqr and the violin plot of price, it is actually the opposite.

In general, the mean and median price of LT transactions are a bit higher than those of ST. Transaction_quantity, however, is a little weird. LT transactions have a higher mean transaction_quantity than ST transactions, but not median. It suggests that LT transaction_quantity are more skewed to the right than ST transactions. The violin plot proves it.

LT transactions has a higher mean and median total_transaction_charge than ST transactions. So price influences total_transaction_charge more than transaction_quantity here. The violin plots of total_transaction_charge of LT and ST look very similar, but LT transactions seem to have more local ups and downs than ST transactions when total transaction charge gets higher.

### Subgroups -- class_name

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by class_name
unique_transaction_count <- energy_daily_data %>%
  group_by(class_name) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = class_name, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Class Name",
    x = "Class Name",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

Firm transactions absolutely dominate EIM. This is perfectly reasonable since no companies or public utilities want the energy sale to be interruptible for economic reasons. In fact, non-firm transactions are the rarest out of the four classes.

```{r echo = FALSE}
energy_daily_data %>%
  group_by(class_name) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity),
    q1_transaction_quantity = quantile(transaction_quantity, 0.25),
    median_transaction_quantity = median(transaction_quantity),
    q3_transaction_quantity = quantile(transaction_quantity, 0.75),
    max_transaction_quantity = max(transaction_quantity),
    mean_transaction_quantity = mean(transaction_quantity),
    sd_transaction_quantity = sd(transaction_quantity),
    iqr_transaction_quantity = IQR(transaction_quantity)
  ) %>%
  pivot_longer(
    cols = -class_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(class_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(transaction_quantity <= 400)

ggplot(processed_data, aes(x = class_name, y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Class Name",
    x = "Class Name",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(class_name) %>%
  summarise(
    min_price = min(price),
    q1_price = quantile(price, 0.25),
    median_price = median(price),
    q3_price = quantile(price, 0.75),
    max_price = max(price),
    mean_price = mean(price), 
    sd_price = sd(price),
    iqr_price = IQR(price)
  ) %>%
  pivot_longer(
    cols = -class_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(class_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(price <= 250)

ggplot(processed_data, aes(x = class_name, y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Class Name",
    x = "Class Name",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(class_name) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge),
    q1_total_transaction_charge = quantile(total_transaction_charge, 0.25),
    median_total_transaction_charge = median(total_transaction_charge),
    q3_total_transaction_charge = quantile(total_transaction_charge, 0.75),
    max_total_transaction_charge = max(total_transaction_charge),
    mean_total_transaction_charge = mean(total_transaction_charge),
    sd_total_transaction_charge = sd(total_transaction_charge),
    iqr_total_transaction_charge = IQR(total_transaction_charge)
  ) %>%
  pivot_longer(
    cols = -class_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(class_name, variable)

processed_data <- energy_daily_data %>% filter(total_transaction_charge <= 25000 & total_transaction_charge >= 1000)

ggplot(processed_data, aes(x = class_name, y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Class Name",
    x = "Class Name",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

First thing I spot here is that transactions classed as firm has the most extreme min and max for all three metrics, except for max transaction_quantity. Mean and median of all three metrics are either the smallest out of the four groups, or second smallest. Combined with what the violin plots show, I can conclude that firm transactions are mostly cheap and small.

Transactions classed as non-firm don't stand out at anything other than the very high sd of total_transaction_charge and total_quantity. So there are a lot of disparity between the non-firm transactions regarding the quantity of energy transacted. The violin plot of transaction_quantity prove it. The violin plot of price shows that price is quite evenly spread out from \$0/MWh to \$150/MWh.

Transactions classed as N/A have the smallest mean and median transaction_quantity, but the highest mean and median price. So transactions classes as N/A are usually small and expensive transactions. The violin plot is the evidence. The This makes sense since law of demand tells us the higher the price, the quantity demanded should be lower. The violin plot of total_transaction_charge of n/a displays that n/a class_name has the least amount of diversity when it comes to total_transaction_charge.

Transactions classed as UP have the highest median, mean and iqr for total_transaction_charge. The mean and median price do not stand out, but those of transaction_quantity do. There are a palpable number of UP transactions that are large and/or expensive. However, the violin plots may argue otherwise. Transaction_quantity is spread evenly. Price is right-skewed and there are a few notable humps in the violin plot. UP transactions have the most uniform distribution of total_transaction_charge out of the four groups. UP transactions are the least homogeneous.

### Subgroups -- increment_name

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by increment_name
unique_transaction_count <- energy_daily_data %>%
  group_by(increment_name) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = increment_name, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Increment Name",
    x = "Increment Name",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

By looking at the graphs and numbers, we can see that the majority (62%) of transactions belong to 2 increment_name groups: D and M. They are followed by Y, H and 5. Y are the long term transactions, and M are short term transactions that have the longest duration. 5 is the hyper short term transactions and H has very short duration too. D is the middle of all these 5 types of transactions.

```{r echo = FALSE}
energy_daily_data %>%
  group_by(increment_name) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity),
    q1_transaction_quantity = quantile(transaction_quantity, 0.25),
    median_transaction_quantity = median(transaction_quantity),
    q3_transaction_quantity = quantile(transaction_quantity, 0.75),
    max_transaction_quantity = max(transaction_quantity),
    mean_transaction_quantity = mean(transaction_quantity),
    sd_transaction_quantity = sd(transaction_quantity),
    iqr_transaction_quantity = IQR(transaction_quantity)
  ) %>%
  pivot_longer(
    cols = -increment_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(increment_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% 
  filter(transaction_quantity <= 60)

ggplot(processed_data, aes(x = increment_name, y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Increment Name",
    x = "Increment Name",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(increment_name) %>%
  summarise(
    min_price = min(price),
    q1_price = quantile(price, 0.25),
    median_price = median(price),
    q3_price = quantile(price, 0.75),
    max_price = max(price),
    mean_price = mean(price), 
    sd_price = sd(price),
    iqr_price = IQR(price)
  ) %>%
  pivot_longer(
    cols = -increment_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(increment_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(price <= 250)

ggplot(processed_data, aes(x = increment_name, y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Increment Name",
    x = "Increment Name",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(increment_name) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge),
    q1_total_transaction_charge = quantile(total_transaction_charge, 0.25),
    median_total_transaction_charge = median(total_transaction_charge),
    q3_total_transaction_charge = quantile(total_transaction_charge, 0.75),
    max_total_transaction_charge = max(total_transaction_charge),
    mean_total_transaction_charge = mean(total_transaction_charge),
    sd_total_transaction_charge = sd(total_transaction_charge),
    iqr_total_transaction_charge = IQR(total_transaction_charge)
  ) %>%
  pivot_longer(
    cols = -increment_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(increment_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(total_transaction_charge <= 1000 & total_transaction_charge >= -100)

ggplot(processed_data, aes(x = increment_name, y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Increment Name",
    x = "Increment Name",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(total_transaction_charge <= 25000 & total_transaction_charge >= -100)

ggplot(processed_data, aes(x = increment_name, y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Increment Name",
    x = "Increment Name",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

Mean shows that transactions with increment_name D, H, N, Y, and W have approximately the same transaction quantity (lowest 105, highest 150 MWh).  Both mean and median shows that extreme short term transactions like 5 and 15 have the lowest transaction quantity in general (much lower in Mwh fact), which makes sense because most of the time it is either impossible to trade more energy or there is not much demand in such a short time (max transaction quantity proves me correct). N/A transaction have the highest mean and median transaction quantity, 400 MWh and 458 MWh respectively.

The violin plot of transaction_quantity is a bit hard to comprehend. There are mainly four types of shapes. 5 and 15 are in the first group. The majority of transaction in this group has a very low transaction quantity. Most transactions with increment name 5 and 15 have transactions lower than 5 and 10 MWh respectively. The distribution of 15 is more uniform, while 5 is more right-skewed. D, H, M, W, Y are in the second group. Transactions are highly concentrated near two transaction quantities: 25 and 50 MWh. The last group is N/A. Its distribution is close to a uniform distribution.

Both mean and median shows that sub 5 minute transactions have the highest price in general, which makes sense because the buyer's demand is usually urgent. However, I do find it interesting that long term transactions (increment_name Y) have higher mean and median price than D, H, M, N/A, and W (except mean M). I think the reason is that in the long run, companies expect the energy price to rise due to inflation (1-5 % per year).

There two main groups in the violin plot of price. 5 and Y are in the first group, the rest in the other. The first group has a more diversified price, ranging from around \$0/MWh to \$125/Mwh. The second group has a less diversified price, mostly in the range \$0/MWh to \$75/MWh. Surprisingly, it seems like there are lots of transactions with M increment_name have near-zero price.

Both mean and median shows that hyper short term transactions (5, 15) have lower total transaction charge than other transactions. This makes sense even though the price is higher on average, the difference between these hyper short term transactions and others lies mainly in transaction quantity. Conversely, long term transactions have a higher mean and median total transaction charge mainly due to a higher price, not transaction quantity.

The violin plot of total transaction charge is very flawed since I only include the transactions with a total transaction charge lower than \$1000. The median total transaction charge for D, H, M, N/A, and Y are already higher than \$1000. I tried a higher limit, but the graph just become meaningless straight lines.

### Subgroups -- transaction_begin_date

The last subgroups we are exploring are the transaction_begin_date. Lets group them by year, quarter, month, days of the month, days of the week. Only mean, median, iqr, sd are needed.

#### Transaction_begin_date -- Year

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by transaction_begin_year
unique_transaction_count <- energy_daily_data %>%
  mutate(transaction_begin_year = year(transaction_begin_date)) %>%  # Extract year from transaction_begin_date
  filter(!is.na(transaction_begin_year)) %>%  # Filter out NA years
  group_by(transaction_begin_year) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = transaction_begin_year, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions over the Years",
    x = "Year",
    y = "Unique Transaction Count"
  ) +
  scale_x_continuous(
    breaks = 2014:2024
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

Energy Trading is 42.1% more active since 2022 than before 2022 (ignore 2024). I believe this could be caused by extreme weather, climate change, and energy crisis in 2021-2023.

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  mutate(transaction_begin_year = year(transaction_begin_date)) %>%  # Extract year from transaction_begin_date
  filter(!is.na(transaction_begin_year)) %>%  # Filter out NA years
  group_by(transaction_begin_year) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity, na.rm = TRUE),
    median_transaction_quantity = median(transaction_quantity, na.rm = TRUE),
    max_transaction_quantity = max(transaction_quantity, na.rm = TRUE),
    mean_transaction_quantity = mean(transaction_quantity, na.rm = TRUE),
    sd_transaction_quantity = sd(transaction_quantity, na.rm = TRUE),
    iqr_transaction_quantity = IQR(transaction_quantity, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_year,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_year, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_year, y = median, color = "Median Transaction Quantity")) +
  geom_point(aes(x = transaction_begin_year, y = median, color = "Median Transaction Quantity")) +
  geom_line(aes(x = transaction_begin_year, y = mean, color = "Mean Transaction Quantity")) +
  geom_point(aes(x = transaction_begin_year, y = mean, color = "Mean Transaction Quantity")) +
  geom_line(aes(x = transaction_begin_year, y = iqr, color = "IQR Transaction Quantity")) +
  geom_point(aes(x = transaction_begin_year, y = iqr, color = "IQR Transaction Quantity")) +
  ylim(0, NA) +
  labs(
    title = "Transaction Quantity Over Years",
    x = "Year",
    y = "Transaction Quantity"
  ) +
  scale_x_continuous(
    breaks = 2014:2024
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by transaction_begin_year
total_transaction_count <- energy_daily_data %>%
  mutate(transaction_begin_year = year(transaction_begin_date)) %>%  # Extract year from transaction_begin_date
  filter(!is.na(transaction_begin_year)) %>%  # Filter out NA years
  group_by(transaction_begin_year) %>%
  summarise(total_transaction_count = n())

# Print the result
print(total_transaction_count)

# Plot the bar chart
ggplot(total_transaction_count, aes(x = transaction_begin_year, y = total_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions over the Years",
    x = "Year",
    y = "Total Transaction Count"
  ) +
  scale_x_continuous(
    breaks = 2014:2024
  ) +
  theme_minimal()

rm(total_transaction_count)
```

```{r echo=FALSE}
# Total Transaction Quantity  = Total Transaction Count * Mean Transaction Quantity
total_transaction_quantity_year <- data.frame(year = 2014:2024, total_transaction_quantity = c(86627399.69, 82590515.35, 75807760.51, 81027722.93, 76667785.07, 65316869.04, 53596084.43, 54427508.1, 63115378.65, 60948450.85, 13167178.77))

ggplot(total_transaction_quantity_year) + 
  geom_line(aes(x = year, y = total_transaction_quantity)) +
  geom_point(aes(x = year, y = total_transaction_quantity)) +
  ylim(0, NA) + 
  labs(
    title = "Total_transaction_quantity By Year",
    x = "Year",
    y = "Total Transaction Quantity"
  ) + 
  scale_x_continuous(
    breaks = 2014:2024
  ) +
  theme_minimal()

rm(total_transaction_quantity_year)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(year(transaction_begin_date))) %>%
  filter(transaction_quantity <= 500)

ggplot(processed_data, aes(x = as.factor(year(transaction_begin_date)), y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Year",
    x = "Year",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```
mi
```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  mutate(transaction_begin_year = year(transaction_begin_date)) %>%  # Extract year from transaction_begin_date
  filter(!is.na(transaction_begin_year)) %>%  # Filter out NA years
  group_by(transaction_begin_year) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_year,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_year, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_year, y = median, color = "Median Price")) +
  geom_point(aes(x = transaction_begin_year, y = median, color = "Median Price")) +
  geom_line(aes(x = transaction_begin_year, y = mean, color = "Mean Price")) +
  geom_point(aes(x = transaction_begin_year, y = mean, color = "Mean Price")) +
  geom_line(aes(x = transaction_begin_year, y = iqr, color = "IQR Price")) +
  geom_point(aes(x = transaction_begin_year, y = iqr, color = "IQR Price")) +
  ylim(0, NA) +
  labs(
    title = "Price Over Years",
    x = "Year",
    y = "Price"
  ) +
  scale_x_continuous(
    breaks = 2014:2024
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(year(transaction_begin_date))) %>% 
  filter(price <= 200)

ggplot(processed_data, aes(x = as.factor(year(transaction_begin_date)), y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Year",
    x = "Year",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
processed_data <- energy_daily_data %>%
  mutate(transaction_begin_year = year(transaction_begin_date)) %>%  # Extract year from transaction_begin_date
  filter(!is.na(transaction_begin_year)) %>%  # Filter out NA years
  group_by(transaction_begin_year) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge, na.rm = TRUE),
    median_total_transaction_charge = median(total_transaction_charge, na.rm = TRUE),
    max_total_transaction_charge = max(total_transaction_charge, na.rm = TRUE),
    mean_total_transaction_charge = mean(total_transaction_charge, na.rm = TRUE),
    sd_total_transaction_charge = sd(total_transaction_charge, na.rm = TRUE),
    iqr_total_transaction_charge = IQR(total_transaction_charge, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_year,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_year, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_year, y = median, color = "Median total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_year, y = median, color = "Median total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_year, y = mean, color = "Mean total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_year, y = mean, color = "Mean total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_year, y = iqr, color = "IQR total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_year, y = iqr, color = "IQR total_transaction_charge")) +
  labs(
    title = "total_transaction_charge Over Years",
    x = "Year",
    y = "total_transaction_charge",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 2014:2024
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(year(transaction_begin_date))) %>% 
  filter(total_transaction_charge <= 10000 & total_transaction_charge >= -1000)

ggplot(processed_data, aes(x = as.factor(year(transaction_begin_date)), y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Year",
    x = "Year",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

The mean transaction_quantity hover around 126 to 160 MWh from 2014 to 2020.  Then, it went down to a decade low point at 93 MWh in 2022 and recovered back to around 120 MWh since 2023. Median transaction_quantity from 2018 to 2020 seems to be almost double the amount in other years. However, I believe this doesn’t mean much since it can be explained by the violin plot of transaction_quantity. Transaction_quantity at certain levels are much more common than others, such as 25 and 50 MWh.

In other words, we now know that the mean transaction_quantity dipped in 2021 and 2022, and we also know that there are more transactions in 2022 and 2023 (especially 2022). It seems like there is a change of energy trading strategy during 2021 to 2023, companies favour more transactions but smaller quantity. If we multiply mean transaction_quantity with total transaction count, we can get the total transaction_quantity in each year to see if more or less energy was traded during those years. The chart created shows an overall downward trend of total transaction_quantity, although it seems like the trend has been slightly reversed since 2020.

The mean and median price hovered around \$20/MWh to \$30/MWh before 2021, bar 2014. Then both mean and median rose tremendously. Median price peaked at \$66/MWh in 2023, while mean price did not stop increasing, hitting \$91/MWh. This can be explained by the energy crisis starting from 2021, caused by multiple reasons such as slow supply recovery after COVID-19 pandemic, geopolitical events, and OPEC's decisions. Oil and gas price rose rapidly, which affected the energy market. Newly implemented policies to combat climate change such as cap-and-invest and carbon tax also play a role in this. The violin plots of price can be grouped into two, pre-2021 and 2021-2024. In the pre-2021 era, price is concentrated below the \$50/MWh level and has a fat center. Price distribution in these years are closer to normal distribution. In 2021-2024, the distribution is much more even, due to the continuously rising and unstable energy price. The violin shape is long and thin, looking more like a uniform distribution.

Both median and mean of total_transaction_charge rose to a higher level starting from 2021. It was caused by price hikes, not transaction_quantity. Again, the violin plot of total_transaction_charge can be grouped into two, pre-2021 and 2021-2024. In the pre-2021 era, it is not so common to see transactions with total_transaction_charge above $2500. The same cannot be said in 2021-2024.

#### Transaction_begin_date -- Quarter

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by transaction_begin_quarter
unique_transaction_count <- energy_daily_data %>%
  mutate(transaction_begin_quarter = quarter(transaction_begin_date)) %>%  # Extract quarter from transaction_begin_date
  filter(!is.na(transaction_begin_quarter)) %>%  # Filter out NA quarters
  filter(year(transaction_begin_date) != 2024) %>% # Filter out 2024 Q1
  group_by(transaction_begin_quarter) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = transaction_begin_quarter, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Quarter",
    x = "Quarter",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

Number of unique transactions in quarters ranked: 3 > 4 > 2 > 1. Note that we didn't count 2024 Q1 to be accurate and fair. On average, the number of transactions in Q3 is 21.4% higher than the number in Q1.

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  mutate(transaction_begin_quarter = quarter(transaction_begin_date)) %>%  # Extract quarter from transaction_begin_date
  filter(!is.na(transaction_begin_quarter)) %>%  # Filter out NA quarters
  group_by(transaction_begin_quarter) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity, na.rm = TRUE),
    median_transaction_quantity = median(transaction_quantity, na.rm = TRUE),
    max_transaction_quantity = max(transaction_quantity, na.rm = TRUE),
    mean_transaction_quantity = mean(transaction_quantity, na.rm = TRUE),
    sd_transaction_quantity = sd(transaction_quantity, na.rm = TRUE),
    iqr_transaction_quantity = IQR(transaction_quantity, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_quarter,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_quarter, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_quarter, y = median, color = "Median transaction_quantity")) +
  geom_point(aes(x = transaction_begin_quarter, y = median, color = "Median transaction_quantity")) +
  geom_line(aes(x = transaction_begin_quarter, y = mean, color = "Mean transaction_quantity")) +
  geom_point(aes(x = transaction_begin_quarter, y = mean, color = "Mean transaction_quantity")) +
  geom_line(aes(x = transaction_begin_quarter, y = iqr, color = "iqr transaction_quantity")) +
  geom_point(aes(x = transaction_begin_quarter, y = iqr, color = "iqr transaction_quantity")) +
  labs(
    title = "transaction_quantity By Quarter",
    x = "Quarter",
    y = "transaction_quantity",
    color = "Statistic"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(quarter(transaction_begin_date))) %>%
  filter(transaction_quantity <= 500)

ggplot(processed_data, aes(x = as.factor(quarter(transaction_begin_date)), y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Quarter",
    x = "Quarter",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# Process the data
processed_data <- energy_daily_data %>%
  mutate(transaction_begin_quarter = quarter(transaction_begin_date)) %>%  # Extract Quarter from transaction_begin_date
  filter(!is.na(transaction_begin_quarter)) %>%  # Filter out NA Quarters
  group_by(transaction_begin_quarter) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_quarter,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_quarter, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_quarter, y = median, color = "Median Price")) +
  geom_point(aes(x = transaction_begin_quarter, y = median, color = "Median Price")) +
  geom_line(aes(x = transaction_begin_quarter, y = mean, color = "Mean Price")) +
  geom_point(aes(x = transaction_begin_quarter, y = mean, color = "Mean Price")) +
  geom_line(aes(x = transaction_begin_quarter, y = iqr, color = "IQR Price")) +
  geom_point(aes(x = transaction_begin_quarter, y = iqr, color = "IQR Price")) +
  labs(
    title = "Price by Quarter",
    x = "Quarter",
    y = "Price",
    color = "Statistic"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(quarter(transaction_begin_date))) %>%
  filter(price <= 250)

ggplot(processed_data, aes(x = as.factor(quarter(transaction_begin_date)), y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Quarter",
    x = "Quarter",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  mutate(transaction_begin_quarter = quarter(transaction_begin_date)) %>%  # Extract quarter from transaction_begin_date
  filter(!is.na(transaction_begin_quarter)) %>%  # Filter out NA Quarters
  group_by(transaction_begin_quarter) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge, na.rm = TRUE),
    median_total_transaction_charge = median(total_transaction_charge, na.rm = TRUE),
    max_total_transaction_charge = max(total_transaction_charge, na.rm = TRUE),
    mean_total_transaction_charge = mean(total_transaction_charge, na.rm = TRUE),
    sd_total_transaction_charge = sd(total_transaction_charge, na.rm = TRUE),
    iqr_total_transaction_charge = IQR(total_transaction_charge, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_quarter,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_quarter, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_quarter, y = median, color = "Median total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_quarter, y = median, color = "Median total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_quarter, y = mean, color = "Mean total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_quarter, y = mean, color = "Mean total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_quarter, y = iqr, color = "iqr total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_quarter, y = iqr, color = "iqr total_transaction_charge")) +
  labs(
    title = "total_transaction_charge By Quarter",
    x = "Quarter",
    y = "total_transaction_charge",
    color = "Statistic"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(quarter(transaction_begin_date))) %>%
  filter(total_transaction_charge <= 25000 & total_transaction_charge >= 1000)

ggplot(processed_data, aes(x = as.factor(quarter(transaction_begin_date)), y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Quarter",
    x = "Quarter",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

Both mean and median indicate that transaction_quantity is the lowest in q3 and q4, and highest in q2. The violin plot of transaction_quantity shows that distribution of transaction_quantity is almost the same for all four quarters, with Q3 having the highest concentration of near-25 MWh transactions. Pacific Northwest relies heavily on hydroelectric power. During Q2, snowmelt from the mountains significantly increase water flows, so more energy is generated. During Q3 and Q4, snowmelt is more depleted, so water flow is the lowest and less energy is generated. Also, due to energy demand for warming, they are less energy surplus in Q4 for trading purposes.

Both mean and median indicate that price is the highest in q3, and lowest in q2. Both sd and iqr shows that price is the most fluctuant in q3, the most stable in q2. From the violin plot, q2 is evidently the most bottom-heavy. q3 has the most transactions with price > \$100/MWh, which causes q3 to have the highest mean price. So we can say that the higher trade price also causes more volatility.

Cooling demand is the highest in q3, and snowmelt slows down in Q3. Supply drops and demand rises, resulting in higher price.

Both mean and median indicate that total_transaction_charge is the highest in q3, and lowest in q2. iqr shows that total_transaction_charge is the most fluctuant in q3, the most stable in q2. Violin plot of total_transaction_charge shows that distribution of total_transaction_charge is almost the same for all four quarters.

From these findings, I can conclude that the main difference that separates the quarters is price, which is driven by the amount of snowmelt. Note that the price patterns in Mid-C and COB may not be universal, since not all regions rely heavily on hydroelectric power and have abundant snowmelt or rainfall.

#### Transaction_begin_date -- Year, Quarter

```{r echo=FALSE, fig.width = 12, fig.height = 3}
# Calculate unique count of transaction_unique_id grouped by transaction_begin_yq
unique_transaction_count <- energy_daily_data %>%
  filter(!is.na(transaction_begin_date)) %>%  # Filter out NA Dates
  mutate(transaction_begin_yq = paste0(year(transaction_begin_date), "-Q", quarter(transaction_begin_date))) %>%  # Extract year and quarter
  group_by(transaction_begin_yq) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = transaction_begin_yq, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions from 2014 Q1 to 2024 Q1",
    x = "Year-Quarter",
    y = "Unique Transaction Count"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(unique_transaction_count)
```

Number of transactions is the lowest in 2021 Q1 (64076), and highest in 2022 Q1 (142074). I believe the global demand recovery after COVID-19 drove up the demand for electricity, so there were more trading activities. 

```{r echo=FALSE, fig.width = 12, fig.height = 4}
processed_data <- energy_daily_data %>%
  filter(!is.na(transaction_begin_date)) %>%  # Filter out NA Dates
  mutate(transaction_begin_yq = paste0(year(transaction_begin_date), "-Q", quarter(transaction_begin_date))) %>%  # Extract year and quarter
  group_by(transaction_begin_yq) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity, na.rm = TRUE),
    median_transaction_quantity = median(transaction_quantity, na.rm = TRUE),
    max_transaction_quantity = max(transaction_quantity, na.rm = TRUE),
    mean_transaction_quantity = mean(transaction_quantity, na.rm = TRUE),
    sd_transaction_quantity = sd(transaction_quantity, na.rm = TRUE),
    iqr_transaction_quantity = IQR(transaction_quantity, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_yq,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_yq, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_yq, y = median, color = "Median Transaction Quantity", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = median, color = "Median Transaction Quantity", group = 1)) +
  geom_line(aes(x = transaction_begin_yq, y = mean, color = "Mean Transaction Quantity", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = mean, color = "Mean Transaction Quantity", group = 1)) +
  geom_line(aes(x = transaction_begin_yq, y = iqr, color = "IQR Transaction Quantity", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = iqr, color = "IQR Transaction Quantity", group = 1)) +
  ylim(0, NA) +
  labs(
    title = "Transaction Quantity from 2014 Q1 to 2024 Q1",
    x = "Year-Quarter",
    y = "Transaction Quantity"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

```{r echo=FALSE, fig.width = 12, fig.height = 4}
processed_data <- energy_daily_data %>%
  filter(!is.na(transaction_begin_date)) %>%  # Filter out NA Dates
  mutate(transaction_begin_yq = paste0(year(transaction_begin_date), "-Q", quarter(transaction_begin_date))) %>%  # Extract year and quarter
  group_by(transaction_begin_yq) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_yq,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_yq, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_yq, y = median, color = "Median Price", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = median, color = "Median Price", group = 1)) +
  geom_line(aes(x = transaction_begin_yq, y = mean, color = "Mean Price", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = mean, color = "Mean Price", group = 1)) +
  geom_line(aes(x = transaction_begin_yq, y = iqr, color = "IQR Price", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = iqr, color = "IQR Price", group = 1)) +
  ylim(0, NA) +
  labs(
    title = "Price from 2014 Q1 to 2024 Q1",
    x = "Year-Quarter",
    y = "Price"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

```{r echo=FALSE, fig.width = 12, fig.height = 4}
processed_data <- energy_daily_data %>%
  filter(!is.na(transaction_begin_date)) %>%  # Filter out NA Dates
  mutate(transaction_begin_yq = paste0(year(transaction_begin_date), "-Q", quarter(transaction_begin_date))) %>%  # Extract year and quarter
  group_by(transaction_begin_yq) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge, na.rm = TRUE),
    median_total_transaction_charge = median(total_transaction_charge, na.rm = TRUE),
    max_total_transaction_charge = max(total_transaction_charge, na.rm = TRUE),
    mean_total_transaction_charge = mean(total_transaction_charge, na.rm = TRUE),
    sd_total_transaction_charge = sd(total_transaction_charge, na.rm = TRUE),
    iqr_total_transaction_charge = IQR(total_transaction_charge, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_yq,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_yq, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_yq, y = median, color = "Median Total Transaction Charge", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = median, color = "Median Total Transaction Charge", group = 1)) +
  geom_line(aes(x = transaction_begin_yq, y = mean, color = "Mean Total Transaction Charge", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = mean, color = "Mean Total Transaction Charge", group = 1)) +
  geom_line(aes(x = transaction_begin_yq, y = iqr, color = "IQR Total Transaction Charge", group = 1)) +
  geom_point(aes(x = transaction_begin_yq, y = iqr, color = "IQR Total Transaction Charge", group = 1)) +
  ylim(0, NA) +
  labs(
    title = "Total Transaction Charge from 2014 Q1 to 2024 Q1",
    x = "Year-Quarter",
    y = "Total Transaction Charge"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

These year-quarter graphs are basically the slightly more detailed version of the year graphs. I did not include violin plots, as there are too many combinations of years and quarters.

Just like the separate transaction_quantity graph for year, here we can see that the mean transaction quantity peaks at 191 MWh in 2018 Q2. The graph that depicts transaction_quantity for quarter also showed that transaction_quantity is the highest in Q2, which is true in most years according to the year-quarter graph.

Just like the price graph by year, we can see that the price started to rise sharply in 2022, Q3 to be precise. This is around the time OPEC+ cut its production, and therefore countries in Europe has a shortage of energy. This drove the price high. Before that, the price also rose due to demand recovery after covid lockdown. The higher price after 2022 Q3 could also be explained by the increasing likelihood of extreme weather events, causing price to skyrocket within a short amount of time and altering the mean price of a quarter (median to a lesser extent). The all time high of mean price is \$120/Mwh in 2022 Q4, and the all time high of median price is \$88/MWh in 2023 Q1.

If we look at the median of total_transaction_charge, it was relatively stable before 2022 Q3, except for 2019 Q1. It doubled in 2022 Q3. Since price also rose during the same period, I can safely say that total_transaction_charge is largely influenced by price, not so much by transaction_quantity.

#### Transaction_begin_date -- Month

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by transaction_begin_month
unique_transaction_count <- energy_daily_data %>%
  mutate(transaction_begin_month = month(transaction_begin_date)) %>%  # Extract Month from transaction_begin_date
  filter(!is.na(transaction_begin_month)) %>%  # Filter out NA Months
  filter(year(transaction_begin_date) != 2024) %>% # Filter out 2024 Q1
  group_by(transaction_begin_month) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = transaction_begin_month, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Month",
    x = "Month",
    y = "Unique Transaction Count"
  ) +
  scale_x_continuous(
    breaks = 1:12, 
    labels = month.abb
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

Number of transactions usually peaks in August (311396), and hits the bottom in February (241131). The peak month has 29.1% more transactions than the bottom month.

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract Month from transaction_begin_date
  mutate(transaction_begin_month = month(transaction_begin_date)) %>%  
  filter(!is.na(transaction_begin_month)) %>%  # Filter out NA Months
  group_by(transaction_begin_month) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity, na.rm = TRUE),
    median_transaction_quantity = median(transaction_quantity, na.rm = TRUE),
    max_transaction_quantity = max(transaction_quantity, na.rm = TRUE),
    mean_transaction_quantity = mean(transaction_quantity, na.rm = TRUE),
    sd_transaction_quantity = sd(transaction_quantity, na.rm = TRUE),
    iqr_transaction_quantity = IQR(transaction_quantity, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_month,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_month, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_month, y = median, color = "Median transaction_quantity")) +
  geom_point(aes(x = transaction_begin_month, y = median, color = "Median transaction_quantity")) +
  geom_line(aes(x = transaction_begin_month, y = mean, color = "Mean transaction_quantity")) +
  geom_point(aes(x = transaction_begin_month, y = mean, color = "Mean transaction_quantity")) +
  geom_line(aes(x = transaction_begin_month, y = iqr, color = "iqr transaction_quantity")) +
  geom_point(aes(x = transaction_begin_month, y = iqr, color = "iqr transaction_quantity")) +
  labs(
    title = "Transaction Quantity By Month",
    x = "Month",
    y = "Transaction Quantity",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:12,
    labels = month.abb
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(month(transaction_begin_date))) %>%
  filter(transaction_quantity <= 500)

ggplot(processed_data, aes(x = as.factor(month(transaction_begin_date)), y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Month",
    x = "Month",
    y = "Transaction Quantity"
  ) +
  scale_x_discrete(
    labels = month.abb
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# Process the data
processed_data <- energy_daily_data %>%
  # Extract Month from transaction_begin_date
  mutate(transaction_begin_month = month(transaction_begin_date)) %>%
  filter(!is.na(transaction_begin_month)) %>%  # Filter out NA months
  group_by(transaction_begin_month) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_month,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_month, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_month, y = median, color = "Median Price")) +
  geom_point(aes(x = transaction_begin_month, y = median, color = "Median Price")) +
  geom_line(aes(x = transaction_begin_month, y = mean, color = "Mean Price")) +
  geom_point(aes(x = transaction_begin_month, y = mean, color = "Mean Price")) +
  geom_line(aes(x = transaction_begin_month, y = iqr, color = "IQR Price")) +
  geom_point(aes(x = transaction_begin_month, y = iqr, color = "IQR Price")) +
  labs(
    title = "Price by Month",
    x = "Month",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:12, 
    labels = month.abb
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(month(transaction_begin_date))) %>%
  filter(price <= 150)

ggplot(processed_data, aes(x = as.factor(month(transaction_begin_date)), y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Month",
    x = "Month",
    y = "Price"
  ) +
  scale_x_discrete(
    labels = month.abb
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract Month from transaction_begin_date
  mutate(transaction_begin_month = month(transaction_begin_date)) %>%
  filter(!is.na(transaction_begin_month)) %>%  # Filter out NA Months
  group_by(transaction_begin_month) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge, na.rm = TRUE),
    median_total_transaction_charge = median(total_transaction_charge, na.rm = TRUE),
    max_total_transaction_charge = max(total_transaction_charge, na.rm = TRUE),
    mean_total_transaction_charge = mean(total_transaction_charge, na.rm = TRUE),
    sd_total_transaction_charge = sd(total_transaction_charge, na.rm = TRUE),
    iqr_total_transaction_charge = IQR(total_transaction_charge, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_month,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_month, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_month, y = median, color = "Median total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_month, y = median, color = "Median total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_month, y = mean, color = "Mean total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_month, y = mean, color = "Mean total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_month, y = iqr, color = "iqr total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_month, y = iqr, color = "iqr total_transaction_charge")) +
  labs(
    title = "total_transaction_charge By Month",
    x = "Month",
    y = "total_transaction_charge",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:12, 
    labels = month.abb
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(month(transaction_begin_date))) %>%
  filter(total_transaction_charge <= 6000 & total_transaction_charge >= -1000)

ggplot(processed_data, aes(x = as.factor(month(transaction_begin_date)), y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Month",
    x = "Month",
    y = "Total Transaction Charge"
  ) +
  scale_x_discrete(
    labels = month.abb
  ) +
  theme_minimal()

rm(processed_data)
```

Median transaction_quantity is in the range 25 to 38 MWh, lowest in January and highest in February. Mean transaction_quantity is in the range 123.7 to 142.7, lowest in August and highest in May. So here the mean and median do not tell the same story. However, we can still see that median transaction_quantity in August is the second lowest on the chart. Median and mean transaction_quantity are in general higher during February to June. This fact aligns with the result we found in the quarter analysis. The violin plot of transaction_quantity shows that no matter what year, transaction_quantity is the most common close to 0, around 25, around 50, around 75, around 100, and around 400. Transaction_quantity  = 25 MWh is the mode in every month. Transaction_quantity is the most concentrated at 25 MWh in January, August and September. These are all months with lower mean transaction_quantity.

Unlike transaction_quantity, both mean and median price show that price of transaction is the lowest from March to June in general, and lowest in May. Both mean and median show that price is higher in the rest of the months, with mean fluctuating more due to extreme values. Price peaks in August and December, which are usually the hottest and coldest months. Note that sd in January, August, September, and December are much higher than the rest of the months, suggesting more extreme weather in these months. A logical conclusion is that higher price correlates with higher sd, which means price volatility brings higher price on average. Transactions in every month are right-skewed, although with different extent. There are also a significant amount of transactions with near-zero prices, which is expected. The shape of violins accurately reflect what line graphs show. From March to June, there are a notable number of transactions with a price about \$10/MWh. The price in the most costly month is 2.6 times higher than the cheapest month on average.

Just like the year analysis, total_transaction_charge moves in an awfully similar way as price. Both mean and median show that total_transaction_charge is the lowest from March to June in general, with May being the trough. total_transaction_charge peaks in August and September according to median and mean. From the violin plot, we can see that the violins of months with a low iqr/mean total_transaction_charge have a more bottom-heavy shape (especially May). More transactions have a near-zero total_transaction_charge.

#### Transaction_begin_date -- Days of the Week

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by transactino_begin_weekday
unique_transaction_count <- energy_daily_data %>%
  # Extract day of the week from transaction_begin_date
  mutate(transaction_begin_weekday = wday(transaction_begin_date, label = TRUE)) %>%
  filter(!is.na(transaction_begin_weekday)) %>%  # Filter out NA day of the week
  group_by(transaction_begin_weekday) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = transaction_begin_weekday, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Day of the Week",
    x = "Day of the Week",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

There are fewer transactions that started on Sunday (14.6% fewer than the average of the rest of the week). Likely because a lot of businesses do not operate or operate at a limited level on Sunday, so less energy is needed.

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the week from transaction_begin_date
  mutate(transaction_begin_weekday = wday(transaction_begin_date, label = TRUE)) %>%
  filter(!is.na(transaction_begin_weekday)) %>%  # Filter out NA day of the week
  group_by(transaction_begin_weekday) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity, na.rm = TRUE),
    median_transaction_quantity = median(transaction_quantity, na.rm = TRUE),
    max_transaction_quantity = max(transaction_quantity, na.rm = TRUE),
    mean_transaction_quantity = mean(transaction_quantity, na.rm = TRUE),
    sd_transaction_quantity = sd(transaction_quantity, na.rm = TRUE),
    iqr_transaction_quantity = IQR(transaction_quantity, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_weekday,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_weekday, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_weekday, y = median, color = "Median transaction_quantity", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = median, color = "Median transaction_quantity")) +
  geom_line(aes(x = transaction_begin_weekday, y = mean, color = "Mean transaction_quantity", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = mean, color = "Mean transaction_quantity")) +
  geom_line(aes(x = transaction_begin_weekday, y = iqr, color = "iqr transaction_quantity", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = iqr, color = "iqr transaction_quantity")) +
  labs(
    title = "transaction_quantity By Day of the Week",
    x = "Day of the Week",
    y = "transaction_quantity",
    color = "Statistic"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(wday(transaction_begin_date))) %>%
  filter(transaction_quantity <= 500)

ggplot(processed_data, aes(x = as.factor(wday(transaction_begin_date)), y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Day of the Week",
    x = "Day of the Week",
    y = "Transaction Quantity"
  ) +
  scale_x_discrete(
    labels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the week from transaction_begin_date
  mutate(transaction_begin_weekday = wday(transaction_begin_date, label = TRUE)) %>%  
  filter(!is.na(transaction_begin_weekday)) %>%  # Filter out NA day of the week
  group_by(transaction_begin_weekday) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_weekday,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_weekday, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_weekday, y = median, color = "Median Price", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = median, color = "Median Price")) +
  geom_line(aes(x = transaction_begin_weekday, y = mean, color = "Mean Price", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = mean, color = "Mean Price")) +
  geom_line(aes(x = transaction_begin_weekday, y = iqr, color = "IQR Price", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = iqr, color = "IQR Price")) +
  labs(
    title = "Price by Day of the Week",
    x = "Day of the Week",
    y = "Price",
    color = "Statistic"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(wday(transaction_begin_date))) %>%
  filter(price <= 200)

ggplot(processed_data, aes(x = as.factor(wday(transaction_begin_date)), y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Day of the Week",
    x = "Day of the Week",
    y = "Price"
  ) +
  scale_x_discrete(
    labels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the week from transaction_begin_date
  mutate(transaction_begin_weekday = wday(transaction_begin_date, label = TRUE)) %>%  
  filter(!is.na(transaction_begin_weekday)) %>%  # Filter out NA day of the week
  group_by(transaction_begin_weekday) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge, na.rm = TRUE),
    median_total_transaction_charge = median(total_transaction_charge, na.rm = TRUE),
    max_total_transaction_charge = max(total_transaction_charge, na.rm = TRUE),
    mean_total_transaction_charge = mean(total_transaction_charge, na.rm = TRUE),
    sd_total_transaction_charge = sd(total_transaction_charge, na.rm = TRUE),
    iqr_total_transaction_charge = IQR(total_transaction_charge, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_weekday,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_weekday, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_weekday, y = median, color = "Median total_transaction_charge", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = median, color = "Median total_transaction_charge", group = 1)) +
  geom_line(aes(x = transaction_begin_weekday, y = mean, color = "Mean total_transaction_charge", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = mean, color = "Mean total_transaction_charge", group = 1)) +
  geom_line(aes(x = transaction_begin_weekday, y = iqr, color = "iqr total_transaction_charge", group = 1)) +
  geom_point(aes(x = transaction_begin_weekday, y = iqr, color = "iqr total_transaction_charge", group = 1)) +
  labs(
    title = "total_transaction_charge by Day of the Week",
    x = "Day of the Week",
    y = "total_transaction_charge",
    color = "Statistic"
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>%
  filter(!is.na(wday(transaction_begin_date))) %>%
  filter(total_transaction_charge <= 10000 & total_transaction_charge >= -1000)

ggplot(processed_data, aes(x = as.factor(wday(transaction_begin_date)), y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Day of the Week",
    x = "Day of the Week",
    y = "Total Transaction Charge"
  ) +
  scale_x_discrete(
    labels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")
  ) +
  theme_minimal()

rm(processed_data)
```

The median transaction_quantity is the lowest on Sunday. It is 23.5% lower than the rest of the week. It makes sense since most businesses do not fully operate on Sunday. However, mean transaction_quantity is the lowest on Wednesday. iqr is the same for all days of the week, so it suggest that there is not much variability on transaction_quantity no matter the day of the week. The violin plot proves that and explains why median transaction_quantity is especially low on Sunday. It is due to the particularly high number of near-25 MWh transactions on Sunday.

Both mean and median show that during the weekend, price is lower, especially on Sunday. This is because less companies demand energy in the weekend (fewer energy transactions), so price is lower according to law of demand. Mean price on Sunday is 17% lower than the rest of the week.

It should not be a surprise that the both mean and median of total_transaction_charge is the lowest on Sunday, since we already know that total_transaction_charge behaves similarly as price (median 25.7% lower than the rest of the week). One interesting thing to note is that iqr is the lowest on Sunday, but sd is the highest. This could mean there are a bit more extreme small and extreme large transactions on Sunday.

Unsurprisingly, since the difference of all three metrics between the days of the week are not prominent, the violin plots of each weekday almost look identical. It appears to me that Sunday has ever so slightly more bottom-heavy distribution.

#### Transaction_begin_date --- Days of the Month

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by transaction_begin_day
unique_transaction_count <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>%
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA day of the month
  group_by(transaction_begin_day) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = transaction_begin_day, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Day of the Month",
    x = "Day of the Month",
    y = "Unique Transaction Count"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(unique_transaction_count)
```

The number of transactions is basically the same every day of the month, except 29, 30, 31 (fewer months contain these days).

``` {r echo=FALSE, fig.width = 10, fig.height = 3}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>%  
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity, na.rm = TRUE),
    median_transaction_quantity = median(transaction_quantity, na.rm = TRUE),
    max_transaction_quantity = max(transaction_quantity, na.rm = TRUE),
    mean_transaction_quantity = mean(transaction_quantity, na.rm = TRUE),
    sd_transaction_quantity = sd(transaction_quantity, na.rm = TRUE),
    iqr_transaction_quantity = IQR(transaction_quantity, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median transaction_quantity")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median transaction_quantity")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean transaction_quantity")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean transaction_quantity")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR transaction_quantity")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR transaction_quantity")) +
  labs(
    title = "Transaction Quantity by Day of the Month",
    x = "Day of the Month",
    y = "Transaction Quantity",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

``` {r echo=FALSE, fig.width = 10, fig.height = 3}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>%  
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  labs(
    title = "Price by Day of the Month",
    x = "Day of the Month",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

``` {r echo=FALSE, fig.width = 10, fig.height = 3}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>%  
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge, na.rm = TRUE),
    median_total_transaction_charge = median(total_transaction_charge, na.rm = TRUE),
    max_total_transaction_charge = max(total_transaction_charge, na.rm = TRUE),
    mean_total_transaction_charge = mean(total_transaction_charge, na.rm = TRUE),
    sd_total_transaction_charge = sd(total_transaction_charge, na.rm = TRUE),
    iqr_total_transaction_charge = IQR(total_transaction_charge, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR total_transaction_charge")) +
  labs(
    title = "Total Transaction Charge by Day of the Month",
    x = "Day of the Month",
    y = "Total Transaction Charge",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

I did not plot any violin plots because there are too many days in a month.

IQR and median of all three metrics are mostly the same every day. The little fluctuation could be random noises.

By eye test, mean price seems to be a be higher in the first half of a month. I can utilize statistical hypothesis testing to determine if mean price is higher in a meaningful way. But first let’s find the distribution of price.

```{r}
# Step 1: Split the data into two groups
group1 <- energy_daily_data %>%
  filter(day(transaction_begin_date) >= 1 & day(transaction_begin_date) <= 16)

group2 <- energy_daily_data %>%
  filter(day(transaction_begin_date) >= 17 & day(transaction_begin_date) <= 31)

group1$group <- "Days 1-16"
group2$group <- "Days 17-31"

combined_data <- rbind(group1, group2) %>% filter(price <= 250 & price >= -20)

# Histogram
ggplot(combined_data, aes(x = price, fill = group)) +
  geom_histogram(aes(y = ..density..), binwidth = 20, alpha = 0.5, position = "identity") +
  labs(
    title = "Distribution of Price by Group",
    x = "Price",
    y = "Density"
  ) +
  theme_minimal()

# Violin plot
ggplot(combined_data, aes(x = group, y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +
  labs(
    title = "Distribution of Price by Group",
    x = "Group",
    y = "Price"
  ) +
  theme_minimal()

combined_data <- rbind(group1, group2)

paste("Mean price in the first half:", mean(group1$price))
paste("Mean price in the second half:", mean(group2$price))

rm(combined_data)
```

The total number of transaction of group1 and group2 is less than that of energy_daily_data. This is because there are rows with an empty transaction_begin_date.

The histogram and violin plot have an range \$20/MWh - \$250/MWh. This is for better visualization.

From the plot, the distribution of price is very skewed to the right for both first half and second half. The distribution of the two groups looks pretty much the same, shown by both the violin plot and histograms.

The distribution is no way near a normal distribution. Unfortunately, we cannot do log transformation or square root transactions due to negative values and the extreme skewness. Traditional hypothesis testing like t-test are not available options. Instead, I am using Mann-Whitney U Test, which is a non-parametric test that does not assume normal distribution.

Mean price is 1.08 times higher in the first half of a month.

Null hypothesis: There is no difference in terms of mean of price between the first half and second half of a month.  
Alternative hypothesis: There is a difference in terms of mean of price between the first half and second half of a month.

I set $\alpha = 0.05$.

```{r}
combined_data <- rbind(group1, group2)

wilcox.test(price~group,
            data = combined_data,
            alternative = 'two.sided')

rm(group1, group2, combined_data)
```

The p-value we got from the test is $2.2 \times 10^{-16}$, which is basically 0. It is way below the threshold of 0.05. Therefore, we reject the null hypothesis. There is a difference in terms of mean of price between the first half and second half of a month. I still don't know the reason yet, but I suspect it is due to seasonal fluctuations. One way to dig deeper is to plot the price charts of days in each month.

##### Days of the Month -- January

``` {r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>% 
  filter(month(transaction_begin_date) == 1) %>%
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  labs(
    title = "Price in January",
    x = "Day of the Month",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

It seems like there is a spike of price in during January 11-16. I researched on Google and found some articles that could be related to it. https://www.publicpower.org/periodical/article/caiso-says-weim-showed-its-value-during-mid-january-cold-event
https://www.reuters.com/business/energy/us-energy-firms-prepare-extreme-freeze-could-hit-natgas-supplies-2024-01-12/
https://powerex.com/sites/default/files/2024-03/Analysis%20of%20the%20January%202024%20Winter%20Weather%20Event.pdf

In these articles, it pointed out that high demand (extreme freezing temperature, winter storms) and plant unavailability (reduced oil and gas production) could be the reason of extreme energy shortage. Substantial imports outside of Pacific Northwest was required and as a result drove up the price.

Let's dig a little deeper by listing the transactions with the highest price.

```{r echo=FALSE}
# Filter for January transactions and sort by price in descending order, top 50 price
energy_daily_data %>%
  filter(month(transaction_begin_date) == 1) %>%
  arrange(desc(price)) %>%
  head(50)
```

All top 50 highest price transactions are short term, one day transactions, which is expected. Most of the transactions occured in 2024, with a few in 2020. Most of them were in the day 11-16 range. So the articles above are correct and we found the reason why the first half of the month has a higher mean price than the second half, but not the median price. Most transactions on the list has RTO/ISO type of rate and are in Mid-C. Seattle City Light sold energy to multiple corporations during this period, including PacifiCorp, Avangrid, Morgan Stanley, Puget Sound. Those transactions have total_transaction_charge greater than \$100000, and price higher than \$1300/MWh.

##### Days of the Month -- March

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>% 
  filter(month(transaction_begin_date) == 3) %>%
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  labs(
    title = "Price in March",
    x = "Day of the Month",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

It seems like there is a spike of price in on March 4th. I researched on Google and found some news that could explain it.
https://www.spglobal.com/commodityinsights/en/market-insights/latest-news/electric-power/030119-mid-columbia-spot-on-peak-power-price-reaches-nearly-900-mwh-hits-over-18-year-high
https://www.eia.gov/todayinenergy/detail.php?id=38932

In the articles, the authors attribute the price spikes due to pipeline and storage maintenance, as well as low temperature caused by polar vortex. The pipeline under maintenance carried gas from Canada into the Pacific Northwest through Sumas. The temperature at that time was averaging 36 F, lower than the historical average by 10 F.

```{r echo=FALSE}
# Filter for March transactions and sort by price in descending order, top 50 price
energy_daily_data %>%
  filter(month(transaction_begin_date) == 3) %>%
  arrange(desc(price)) %>%
  head(200)
```

Most of the top 200 highest price transactions were around March 4th, 2019. Mid-C dominates the top 200 list. Most transactions on top 200 has fixed type_of_rate. These facts matches with the news I found. Again, most transactions are ST on the top 200 list.

There is a SCL transaction in the top 200 higest price transactions. Seattle City Light sold 4 MWh energy to Turlock Irrigation District, with price \$900/MWh.

##### Days of the Month -- August

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>% 
  filter(month(transaction_begin_date) == 8) %>%
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  labs(
    title = "Price in August",
    x = "Day of the Month",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

The mean price shoots up to more than \$80/MWh on August 16th. I researched on the internet and found these news and reports. 

https://www.spglobal.com/commodityinsights/en/market-insights/latest-news/electric-power/081523-caiso-wind-generation-falls-thermal-rises-as-power-prices-reach-record-highs
https://www.caiso.com/documents/summermarketperformancereportforaugust2023.pdf

In the Caiso report, it mentioned that the experienced temperature was 3 F higher than normal. The hourly average load was the highest on August 16th. A drop in wind and solar generation was the other reason that drove up power prices.

Again, let's list the top 100 highest price transactions in August to explore more.

```{r echo=FALSE}
# Filter for August transactions and sort by price in descending order, top 50 price
energy_daily_data %>%
  filter(month(transaction_begin_date) == 8) %>%
  arrange(desc(price)) %>%
  head(100)
```

More than half of these transactions began on August 16th, 2023. However, a considerable number of transactions have a trade date more than a month earlier than August 16th. The vast majority of the transactions occured in 2023, which matches the year the news was published. Most transactions on the top 100 list has electric index type of rate annd are in COB. Seattle City light was the seller of a couple of transactions. We sold energy to Avangrid, Eugene Water and Electric Board, PacifiCorp. These transactions have quantity ranged from 25 to 125 MWh, price ranged from \$1200 to \$1800/MWh.

##### Days of the Month -- September

``` {r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>% 
  filter(month(transaction_begin_date) == 9) %>%
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  labs(
    title = "Price in September",
    x = "Day of the Month",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:30, 
    labels = 1:30
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

There are two anomalies here. The peak on the 1st and 2nd of September, and a lower one on the 6th. Here are some links that state some potential reasons.

https://www.washingtonpolicy.org/publications/detail/californias-energy-problems-are-affecting-washington-state-electricity-prices
https://energyathaas.wordpress.com/2022/09/12/how-high-did-californias-electricity-prices-get/
https://www.eia.gov/todayinenergy/detail.php?id=55139

From eia, it mentioned that there was a heat wave in the western US in early September. From Energy Institute at HAAS, we know that electricity demand was pushed to an all time high. Expensive natural gas-fired generation increased at that time. If we combine these facts, a price surge is a logical response.

```{r echo=FALSE}
# Filter for September transactions and sort by price in descending order, top 50 price
energy_daily_data %>%
  filter(month(transaction_begin_date) == 9) %>%
  arrange(desc(price)) %>%
  head(200)
```

Surprisingly, most of the transactions in the top 100 were traded between PGE and California ISO in 2022. Almost all transactions were ST and in Mid-C in the top 200 list. The transactions all have electric index or RTO/ISO type_of_rate, and one day duration. These facts suggest there was an emergency in California, which was true according to the news. There are two transactions in the top 200 highest price list involving Seattle City Light, both of which we sold 25 MWh energy to CAISO with price higher than \$1030/MWh.

##### Days of the Month -- December

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  # Extract day of the month from transaction_begin_date
  mutate(transaction_begin_day = day(transaction_begin_date)) %>% 
  filter(month(transaction_begin_date) == 12) %>%
  filter(!is.na(transaction_begin_day)) %>%  # Filter out NA days
  group_by(transaction_begin_day) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_day,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_day, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_point(aes(x = transaction_begin_day, y = median, color = "Median price")) +
  geom_line(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_point(aes(x = transaction_begin_day, y = mean, color = "Mean price")) +
  geom_line(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  geom_point(aes(x = transaction_begin_day, y = iqr, color = "IQR price")) +
  labs(
    title = "Price in December",
    x = "Day of the Month",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(
    breaks = 1:31, 
    labels = 1:31
  ) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

rm(processed_data)
```

There are two price peaks, one is on the 12th, the other on the 22nd. Here are some links that could provide some information on why there were peaks on these days.

https://www.ferc.gov/sites/default/files/2023-03/2022_State-of-the-market.pdf
https://www.caiso.com/documents/gas-conditions-and-caiso-markets-report-for-dec2022-jan2023.pdf
https://en.wikipedia.org/wiki/December_2022_North_American_winter_storm

It seems like the two peaks are actually from the same year, 2022. There was a winter storm in December 2022. Extreme winter weather on December 23-25 increased natural gas and electricity demand acorss the US, and also restricted the production of natural gas. From the caiso document, it also stated that low gas storage could be a reason. Earlier heatwaves in the summer (the one I discussed in September 2022) used up lots of natural gas in storage inventories. Another factor is the lower hydro generation in the West.

```{r echo=FALSE}
# Filter for December transactions and sort by price in descending order, top 50 price
energy_daily_data %>%
  filter(month(transaction_begin_date) == 12) %>%
  arrange(desc(price)) %>%
  head(100)
```

The trade date of almost all transactions on the top 100 highest price list is around December 22, 2022. Most of them were short term trades through Mid-C. All of them has one day duration. These information suggests there was an emergency, which was the windstorm. Seattle City sold energy to several customers, including PUD NO.1 of Snohomish County, CAISO, Northwestern Energy, and Shell. During this time, we sold energy with a price higher than \$600/MWh and transaction_quantity bewteen 25 MWh and 150 MWh in each transaction.

##### Days of the Month -- Key findings

Since most of the unexpected extreme weather that led to demand surge and suppy difficulties occured in the first half of the month, it made sense that the mean price of the first half is higher than the second half. It is just a coincidence that most of these events occured in the same half. If we ignore the days that these events happened, the mean price is probably highly similar, just like the median price.

Another thing I discovered here is the fact that unexpected extreme weather is hitting America more frequently recently. All five of the events I mentioned happened in 2019 or after. Climate risk is playing a bigger role in energy trading (day-ahead and real-time markets).

### Subgroups -- point_of_delivery_specific_location
#### Hub Basic Descriptive Statistics

The last subgroup I will explore is point_of_delivery_specific_location, or trading hub in this scenario. Let's see if there is any significant difference between the two hubs -- COB and Mid-Columbia (Mid-C).

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by point_of_delivery_specific_location
unique_transaction_count <- energy_daily_data %>%
  group_by(point_of_delivery_specific_location) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = point_of_delivery_specific_location, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Point of Delivery Specific Location",
    x = "Point of Delivery Specific Location",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

Mid-Columbia (Mid-C) has 5.4 times more energy transactions than California Oregon Border (COB) [1835999 vs 339984].

```{r echo = FALSE}
energy_daily_data %>%
  group_by(point_of_delivery_specific_location) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity),
    q1_transaction_quantity = quantile(transaction_quantity, 0.25),
    median_transaction_quantity = median(transaction_quantity),
    q3_transaction_quantity = quantile(transaction_quantity, 0.75),
    max_transaction_quantity = max(transaction_quantity),
    mean_transaction_quantity = mean(transaction_quantity),
    sd_transaction_quantity = sd(transaction_quantity),
    iqr_transaction_quantity = IQR(transaction_quantity)
  ) %>%
  pivot_longer(
    cols = -c(point_of_delivery_specific_location),
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(point_of_delivery_specific_location, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(transaction_quantity <= 500)

ggplot(processed_data, aes(x = point_of_delivery_specific_location, y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Point of Delivery Specific Location",
    x = "Point of Delivery Specific Location",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(point_of_delivery_specific_location) %>%
  summarise(
    min_price = min(price),
    q1_price = quantile(price, 0.25),
    median_price = median(price),
    q3_price = quantile(price, 0.75),
    max_price = max(price),
    mean_price = mean(price), 
    sd_price = sd(price),
    iqr_price = IQR(price)
  ) %>%
  pivot_longer(
    cols = -point_of_delivery_specific_location,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(point_of_delivery_specific_location, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(price <= 250)

ggplot(processed_data, aes(x = point_of_delivery_specific_location, y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Point of Delivery Specific Location",
    x = "Point of Delivery Specific Location",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_daily_data %>%
  group_by(point_of_delivery_specific_location) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge),
    q1_total_transaction_charge = quantile(total_transaction_charge, 0.25),
    median_total_transaction_charge = median(total_transaction_charge),
    q3_total_transaction_charge = quantile(total_transaction_charge, 0.75),
    max_total_transaction_charge = max(total_transaction_charge),
    mean_total_transaction_charge = mean(total_transaction_charge),
    sd_total_transaction_charge = sd(total_transaction_charge),
    iqr_total_transaction_charge = IQR(total_transaction_charge)
  ) %>%
  pivot_longer(
    cols = -point_of_delivery_specific_location,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(point_of_delivery_specific_location, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_daily_data %>% filter(total_transaction_charge <= 20000 & total_transaction_charge >= -1000)

ggplot(processed_data, aes(x = point_of_delivery_specific_location, y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Point of Delivery Specific Location",
    x = "Point of Delivery Specific Location",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

Mid-C has a lower median transaction_quantity but a slightly higher mean. Its sd is more than double of COB's sd. That means in general, Mid-C sells a bit less energy per day in a transaction, except for a few huge transactions. The violin plot shows that transaction_quantity in Mid-C is very concentrated in a few values. The transaction_quantity in COB is also quite concentrated, but less so than in Mid-C.

Interestingly, the median and mean of price is basically the same for both location. sd of COB is slightly higher due to extreme large and small values. The violin plots show that Mid-C and COB has pretty much the same violin shape for the most part. However, Mid-C has a lot of transactions with a near-zero price, while COB has a quite a lot of transactions around \$55/MWh.

total_transaction_charge is usually a bit higher in COB than Mid-C, demonstrated by both mean and median. This makes sense since median of transaction_quantity and price are higher in COB than Mid-C. The extremely high max total_transaction_charge in Mid-C can be attributed to its extremely high transaction_quantity (price less so). The violin plot shows that Mid-C has a lot of transactions with a near-zero total_transaction_charge, likely due to price.

#### Number of Companies in Each Hub

Next we are going to find the number of companies that conducted energy trade in COB and Mid-C respectively.

```{r echo = FALSE}
energy_daily_data %>%
  group_by(point_of_delivery_specific_location) %>%
  summarise(
    unique_seller_count = n_distinct(seller_company_name),
    unique_customer_count = n_distinct(customer_company_name)
  )
```

47 companies sold energy via COB, while 72 companies sold energy via Mid-C. 317 companies buy energy via COB, while 694 companies buy energy via Mid-C. The numbers show that more companies had transaction at Mid-C than COB.

Please note that the numbers of customers in both hubs are overstated, due to different naming of customers by the company that filed the EQR (the seller).

#### Ranking the companies

It's time to rank the sum of transaction_quantity (energy transaction quantity, unit MWh) and total_transaction_charge (transaction dollar amount, unit $USD) in each hub. I will separate seller and customer analysis.

```{r echo=FALSE}
# Calculate the sum of transaction_quantity for each seller and rank them
ranked_sellers_cob <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "COB") %>%
  group_by(seller_company_name) %>%
  summarise(total_transaction_quantity = sum(transaction_quantity, na.rm = TRUE)) %>%
  arrange(desc(total_transaction_quantity))

# Create a new data frame for the top 5 sellers and others
top_sellers <- ranked_sellers_cob %>%
  slice(1:5) %>%
  mutate(seller_company_name = factor(seller_company_name, levels = seller_company_name))

others <- ranked_sellers_cob %>%
  slice(6:n()) %>%
  summarise(seller_company_name = "Others",
            total_transaction_quantity = sum(total_transaction_quantity))

# Combine the top 5 sellers and others into one data frame
combined_data <- bind_rows(top_sellers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = total_transaction_quantity, fill = seller_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Sellers in COB by Total Transaction Quantity",
    fill = "Seller"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_sellers_cob)
rm(combined_data, others, ranked_sellers_cob, top_sellers)
```

The top 5 energy sellers in COB in terms of total transaction_quantity are:  

1. Avangrid Renewables -- 25688560 MWh  
2. Bonneville Power Administration (BPA) -- 25659650 MWh  
3. Shell Energy -- 21233390 MWh  
4. Iberdrola Renewables -- 9039209 MWh  
5. PacifiCorp -- 7778330 MWh

** Note that Iberdrola owns 81.5% of Avangrid, Inc. Iberdrola is the parent company of Avangrid.

3 Companies sold more than 10000000 MWh in COB.  
14 Companies sold more than 1000000 and less than 10000000 MWh in COB.  
15 Companies sold more than 100000 and less than 1000000 MWh in COB.  
9 Companies sold more than 10000 and less than 100000 MWh in COB.  
6 Companies sold less than 10000 MWh in COB.

Some companies did not generate energy themselves, such as Morgan Stanley.

From the pie chart, we can see the approximate market share. Avangrid, BPA, and Shell each has about 17-18% of market share. Iberdrola has around 7% and PGE has around 5%.

Seattle City Light ranks 14th in this regard. We sold 2323380 Mwh in the past 10 years, about 9% of the total amount of energy Avangrid Renewables sold in COB.

```{r echo=FALSE}
# Calculate the sum of transaction_quantity for each customer and rank them
ranked_customers_cob <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "COB") %>%
  group_by(customer_company_name) %>%
  summarise(total_transaction_quantity = sum(transaction_quantity, na.rm = TRUE)) %>%
  arrange(desc(total_transaction_quantity))

# Create a new data frame for the top 5 customers and others
top_customers <- ranked_customers_cob %>%
  slice(1:5) %>%
  mutate(customer_company_name = factor(customer_company_name, levels = customer_company_name))

others <- ranked_customers_cob %>%
  slice(6:n()) %>%
  summarise(customer_company_name = "Others",
            total_transaction_quantity = sum(total_transaction_quantity))

# Combine the top 5 customers and others into one data frame
combined_data <- bind_rows(top_customers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = total_transaction_quantity, fill = customer_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Customers in COB by Total Transaction Quantity",
    fill = "Customer"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_customers_cob)
rm(combined_data, others, ranked_customers_cob, top_customers)
```

** Note that the information below is not entirely accurate since sellers file EQR and names of buyers are not standardized, a buyer might have multiple similar names. They are hard to be grouped in R.

The top 5 energy buyers in COB in terms of total transaction_quantity are:

1. Sacramento Municipal Utility District (SMUD) -- 19792340 MWh  
2. CALIFORNIA INDEPENDENT SYSTEMS OPERATION CORP DBA CALIF (Cal DBA) -- 15451740 MWh  
3. Modesto Irrigation District (MID) -- 9367080 MWh  
4. Southern California Edison (SCE) -- 6842167 MWh  
5. Turlock Irrigation District -- 6006494 MWh

2 Companies purchased more than 10000000 MWh in COB.  
26 Companies purchased more than 1000000 and less than 10000000 MWh in COB.  
66 Companies purchased more than 100000 and less than 1000000 MWh in COB.  
77 Companies purchased more than 10000 and less than 100000 MWh in COB.  
61 Companies purchased more than 1000 and less than 10000 MWh in COB.  
63 Companies purchased more than 100 and less than 1000 MWh in COB.  
22 Companies purchased less than 100 MWh in COB.

All top 5 energy buyers are from California. In fact, out of the top 10, only Exelon is not in California now. However, even Exelon used to own power plants in California before transferring its power generation assets to Constellation Energy Corp.

Meanwhile, the top 10 sellers are a lot more diverse when considering the location grouped by states (Oregon, Washington, Maryland, British Columbia, Texas). Some sellers even have tremendous presence in multiple states.

From the pie chart, we can see the rough proportion of energy they purchase. SMUD purchased around 15% of energy, Cal DBA around 12%, MID roughly 7%. The energy buyer market of COB is less of an oligopoly when compared to the energy seller market of COB, which is reasonable because there were a lot more buyers than sellers in COB energy market.

Seattle City Light bought 16252.5 MWh of energy. We are quite insignificant here because obviously Seattle City Light is an energy net exporter most of the time. (8463.3 + 3661 + 2517 + 900 + 711.2, from 5 different names)

```{r echo=FALSE}
# Calculate the sum of total_transaction_charge for each seller and rank them
ranked_sellers_cob <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "COB") %>%
  group_by(seller_company_name) %>%
  summarise(revenue = sum(total_transaction_charge, na.rm = TRUE)) %>%
  arrange(desc(revenue))

# Create a new data frame for the top 5 sellers and others
top_sellers <- ranked_sellers_cob %>%
  slice(1:5) %>%
  mutate(seller_company_name = factor(seller_company_name, levels = seller_company_name))

others <- ranked_sellers_cob %>%
  slice(6:n()) %>%
  summarise(seller_company_name = "Others",
            revenue = sum(revenue))

# Combine the top 5 sellers and others into one data frame
combined_data <- bind_rows(top_sellers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = revenue, fill = seller_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Sellers in COB by Revenue",
    fill = "Seller"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_sellers_cob)
rm(combined_data, others, ranked_sellers_cob, top_sellers)
```

The top 5 energy sellers in COB in terms of revenue are:  

1. Bonneville Power Administration (BPA) -- $1090043000  
2. Avangrid Renewables -- $964593700    
3. Shell Energy -- $881839600  
4. Iberdrola Renewables -- $284185900  
5. Portland General Electric (PGE) -- $281868400 

1 Company sold energy and earned more than \$1000000000 in COB.  
12 Companies sold energy and earned more than \$100000000 and less than \$1000000000 in COB.  
13 Companies sold energy and earned more than \$10000000 and less than \$100000000 in COB.  
13 Companies sold energy and earned more than \$1000000 and less than \$10000000 in COB.  
4 Companies sold energy and earned more than \$100000 and less than \$1000000 in COB.  
4 Companies sold energy and earned less than \$100000 in COB.

The top 5 sellers in COB in terms of revenue are basically the same as in terms of transaction_quantity, which makes sense. The only difference being BPA ahead of Avangrid Renewables when we consider revenue instead of transaction_quantity, which means Avangrid Renewables sold energy at a lower price than BPA.

From the pie chart, we can see the approximate market share again. BPA, Avangrid and Shell each has about 16-18% of market share again. The table shows that Powerex Corp. is exceptional at generating revenue by selling energy, since it only ranks 9th in quantity sold in COB, but 6th in revenue. Arlington Wind Power is another excellent company at generating revenue by selling energy. It ranks 9th in revenue, but only 18th in quantity sold.

Seattle City Light earned a total of \$90790870 by selling energy in COB. We rank 15th and earned about 8.3% of the revenue BPA earned, 9.4% of the revenue Avangrid earned when selling energy in COB. Therefore, we sold energy at a higher price than Avangrid too.

```{r echo=FALSE}
# Calculate the sum of total_transaction_charge for each customer and rank them
ranked_customers_cob <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "COB") %>%
  group_by(customer_company_name) %>%
  summarise(expense = sum(total_transaction_charge, na.rm = TRUE)) %>%
  arrange(desc(expense))

# Create a new data frame for the top 5 customers and others
top_customers <- ranked_customers_cob %>%
  slice(1:5) %>%
  mutate(customer_company_name = factor(customer_company_name, levels = customer_company_name))

others <- ranked_customers_cob %>%
  slice(6:n()) %>%
  summarise(customer_company_name = "Others",
            expense = sum(expense))

# Combine the top 5 customers and others into one data frame
combined_data <- bind_rows(top_customers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = expense, fill = customer_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Customers in COB by Expense",
    fill = "Customer"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_customers_cob)
rm(combined_data, others, ranked_customers_cob, top_customers)
```

** Note that the information below is not entirely accurate since sellers file EQR and names of buyers are not standardized, a buyer might have multiple similar names. They are hard to be grouped in R.

The top 5 energy buyers in COB in terms of expense are:

1. Sacramento Municipal Utility District (SMUD) -- $1022124000
2. CALIFORNIA INDEPENDENT SYSTEMS OPERATION CORP DBA CALIF (Cal DBA) -- $571494000
3. Modesto Irrigation District (MID) -- $335716300
4. Pacific Gas and Electric Company (PG&E) -- $333503700
5. Southern California Edison Company (SCE) -- $281829400

1 company pucharsed energy and spent more than \$1000000000 in COB.  
9 Companies purchased energy and spent more than \$100000000 in COB.  
58 Companies purchased energy and spent more than \$10000000 and less than \$100000000 in COB.  
71 Companies purchased energy and spent more than \$1000000 and less than \$10000000 in COB.  
69 Companies purchased energy and spent more than \$100000 and less than \$1000000 in COB.  
65 Companies purchased energy and spent more than \$10000 and less than \$100000 in COB.  
44 Companies purchased energy and spend less than \$10000 in COB.

Only Arlington Wind Power Project and Exelon are not from California in the top 10 spender. Arlington locates in Oregon and Exelon is based in Baltimore, Maryland .              .

4 out of top 5 buyers in COB are the same when we count in terms of expense and transaction_quantity. The only exception is PG&E replaces Turlock. M-S-R actually ranks 26, so logically that means M-S-R usually buy cheaper energy when compared to other top buyers.

From the pie chart, we can see the rough proportion of money they spend on energy in the market. SMUD spent around 18% of money, CAISO around 10%, MID and PG&E roughtly 5%, SCE approximately 4%. When considering expense, the energy buyer market of COB is still less of an oligopoly when compared to the energy seller market of COB.

Seattle City Light spent \$405288.6 (199462.7 + 86267.7 + 73015 + 25243.2 + 21300, from 5 different names). Again, we were quite an unimportant buyer in COB. We have a net income of 90790870 - 405288.6 = \$90385581 in the last 10 years participating in energy transaction in COB. I didn't account for other cost of good sold when calculating net income.

After ranking the companies in COB, let's start ranking the companies in Mid-C.

```{r echo=FALSE}
# Calculate the sum of transaction_quantity for each seller and rank them
ranked_sellers_midc <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "MID-COLUMBIA (MID-C)") %>%
  group_by(seller_company_name) %>%
  summarise(total_transaction_quantity = sum(transaction_quantity, na.rm = TRUE)) %>%
  arrange(desc(total_transaction_quantity))

# Create a new data frame for the top 5 sellers and others
top_sellers <- ranked_sellers_midc %>%
  slice(1:5) %>%
  mutate(seller_company_name = factor(seller_company_name, levels = seller_company_name))

others <- ranked_sellers_midc %>%
  slice(6:n()) %>%
  summarise(seller_company_name = "Others",
            total_transaction_quantity = sum(total_transaction_quantity))

# Combine the top 5 sellers and others into one data frame
combined_data <- bind_rows(top_sellers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = total_transaction_quantity, fill = seller_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Sellers in Mid-C by Total Transaction Quantity",
    fill = "Seller"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_sellers_midc)
rm(combined_data, others, ranked_sellers_midc, top_sellers)
```

The top 5 energy sellers in Mid-C in terms of total transaction_quantity are:  

1. Shell Energy -- 67032560 MWh  
2. TransAlta Centralia Generation -- 52977160 Mwh
3. Bonneville Power Administration (BPA) -- 52472390 MWh
4. Public Utility District No 1 of Chelan County (PUD Chelan) -- 38862960 MWh
5. TransAlta Energy Marketing -- 38601220 MWh

18 Companies sold more than 10000000 MWh in Mid-C.    
20 Companies sold more than 1000000 and less than 10000000 MWh in Mid-C.    
18 Companies sold more than 100000 and less than 1000000 MWh in Mid-C.    
6 Companies sold more than 10000 and less than 100000 MWh in Mid-C.    
10 Companies sold less than 10000 MWh in Mid-C.  

Again, some companies did not generate energy themselves, such as Morgan Stanley and EDF Trading.

Shell mainly generated energy in California and British Columbia, and mainly traded energy in California. It is based in Houston, Texas. Avangrid mainly generated energy in Oregon. EDF Trading does not generate energy themselves and is based in Houston. The rest mainly operated in Washington when they traded energy via Mid-C trading hub.

There are two TransAlta entities on the top 5 list. They are both subsidiaries of TransAlta Corporation, a Canadian Company based in Calgary, Alberta. If I add up their transaction_quantity, TransAlta will be no.1 on the list.

From the pie chart, we can see the approximate market share. Shell has around 12.5%, TransAlta Centralia and BPA about 10%, PUD Chelan and TransAlta Energy Marketing about 7%. Avangrid and Puget Sound Energy each consists of nearly 5%. The proportion of others here is larger than the respective proportion of others in COB.

Seattle City Light ranks 11th in this regard, compared to 14th in COB. We sold 19419080 MWh via Mid-C in the past 10 years, which is almost 8.4 times of the amount we sold via COB. 19419080 MWh is close to 30% of the total amount of energy Shell sold, compared to 9% of the top seller in COB. So, both proportion and absolute value indicates that our presence is more felt in Mid-C than COB. It it very reasonable since Mid-C resides in Washington.

```{r echo=FALSE}
# Calculate the sum of transaction_quantity for each customer and rank them
ranked_customers_midc <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "MID-COLUMBIA (MID-C)") %>%
  group_by(customer_company_name) %>%
  summarise(total_transaction_quantity = sum(transaction_quantity, na.rm = TRUE)) %>%
  arrange(desc(total_transaction_quantity))

# Create a new data frame for the top 5 customers and others
top_customers <- ranked_customers_midc %>%
  slice(1:5) %>%
  mutate(customer_company_name = factor(customer_company_name, levels = customer_company_name))

others <- ranked_customers_midc %>%
  slice(6:n()) %>%
  summarise(customer_company_name = "Others",
            total_transaction_quantity = sum(total_transaction_quantity))

# Combine the top 5 customers and others into one data frame
combined_data <- bind_rows(top_customers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = total_transaction_quantity, fill = customer_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Customers in Mid-C by Total Transaction Quantity",
    fill = "Customer"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_customers_midc)
rm(combined_data, others, ranked_customers_midc, top_customers)
```

** Note that the information below is not entirely accurate since sellers file EQR and names of buyers are not standardized, a buyer might have multiple similar names. They are hard to be grouped in R.

The top 5 energy buyers in Mid-C in terms of total transaction_quantity are:

1. TransAlta Energy Marketing (U.S.) Inc. -- 55647920 MWh  
2. Powerex Corp. -- 27254700 MWh
3. Shell Energy -- 27134070 MWh
4. Puget Sound Energy (PSE) -- 26638400 MWh  
5. PacifiCorp -- 22647630 MWh  

12 Companies purchased more than 10000000 MWh in Mid-C.  
87 Companies purchased more than 1000000 and less than 10000000 MWh in Mid-C.  
178 Companies purchased more than 100000 and less than 1000000 MWh in Mid-C.  
174 Companies purchased more than 10000 and less than 100000 MWh in Mid-C.  
111 Companies purchased more than 1000 and less than 10000 MWh in Mid-C.  
79 Companies purchased more than 100 and less than 1000 MWh in Mid-C.  
53 Companies purchased less than 100 MWh in Mid-C.

TransAlta is based in Alberta and Powerex is based in British Columbia. Puget Sound Energy is based in Washington. PacifiCorp mainly traded in Oregon. Shell generated energy in California and Western Canada, and traded everywhere. So the top energy buyers in Mid-C are a lot more diverse than the those in COB. Canada also comes into play due to proximity. 

From the pie chart, we can see the rough proportion of energy they purchase. TransAlta Energy Marketing contributed roughly 9%. Shell, Powerex, PSE purchased around 4-5% of energy. PacifiCorp purchased about 3.5% of energy. Same as the situation in COB, the energy buyer market of MId-C has a lot of competition when compared to the energy seller market of Mid-C due to the inequality of number of companies involved. The market proportion of others here is also larger than the respective proportion of others in COB, which is logical because there is more than double amount of buyers in Mid-C than in COB.

Seattle City Light bought 5091231 MWh of energy. We are a lot more significant here than in COB. We bought a whopping 313 times more energy via Mid-C. 5091231 is about 9.1% of the amount the no.1 company purchased. (3234753 + 713280.3 + 590909 + 198604 + 178645.1 + 121024.4 + 44356 + 9443.7 + 215, from 9 different names)

```{r echo=FALSE}
# Calculate the sum of total_transaction_charge for each seller and rank them
ranked_sellers_midc <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "MID-COLUMBIA (MID-C)") %>%
  group_by(seller_company_name) %>%
  summarise(revenue = sum(total_transaction_charge, na.rm = TRUE)) %>%
  arrange(desc(revenue))

# Create a new data frame for the top 5 sellers and others
top_sellers <- ranked_sellers_midc %>%
  slice(1:5) %>%
  mutate(seller_company_name = factor(seller_company_name, levels = seller_company_name))

others <- ranked_sellers_midc %>%
  slice(6:n()) %>%
  summarise(seller_company_name = "Others",
            revenue = sum(revenue))

# Combine the top 5 sellers and others into one data frame
combined_data <- bind_rows(top_sellers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = revenue, fill = seller_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Sellers in Mid-C by Revenue",
    fill = "Seller"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_sellers_midc)
rm(combined_data, others, ranked_sellers_midc, top_sellers)
```

The top 5 energy sellers in Mid-C in terms of revenue are:  

1. TransAlta Centralia Generation -- \$2348233000  
2. Shell Energy -- \$2303764000  
3. Public Utility District No 1 of Chelan County (PUD Chelan) -- \$1436986000  
4. TransAlta Energy Marketing -- \$1421184000  
5. ConocoPhillips -- \$1341030000

8 Companies sold energy and earned more than \$1000000000 in Mid-C.  
22 Companies sold energy and earned more than \$100000000 and less than \$1000000000 in Mid-C.  
21 Companies sold energy and earned more than \$10000000 and less than \$100000000 in Mid-C.  
11 Companies sold energy and earned more than \$1000000 and less than \$10000000 in Mid-C.  
3 Companies sold energy and earned more than \$100000 and less than \$1000000 in Mid-C.  
7 Companies sold energy and earned less than \$100000 in Mid-C.

The top 5 sellers in Mid-C in terms of revenue looks quite different from the top 5 in terms of total transaction_quantity. First of all, ConocoPhillips breaks into top 5, and BPA fells to no.9. In fact, BPA sold 2.4 times the energy ConocoPhilips sold, but only shockingly earned 67.8% of revenue from selling energy via Mid-C. Therefore, ConocoPhilips must be selling energy at quite a high price and BPA at quite a low price when compared to other members in the market. TransAlta Centralia and Shell switch their ranking. PUD Chelan and TransAlta Energy Marketing rises to no.3 and no.4 respectively.

From the pie chart, we can see the approximate market share again. TransAlta Centralia and Shell each holds about 11%. The rest of the top 5 have around 6-7% market share when we use revenue as the measure.

Seattle City Light earned a total of \$505864700 from selling energy via Mid-C in the last 10 years. We rank 15th and earned about 22% of the revenue TransAlta Centralia or Shell earned. Therefore, we must be selling energy at a lower price than the leading sellers. \$505864700 is 5.6 times of revenue in COB. Since we sold 8.4 times more energy via Mid-C, that means we generated less revenue but with more efficiency in COB (lower operating ratio).

```{r echo=FALSE}
# Calculate the sum of total_transaction_charge for each customer and rank them
ranked_customers_midc <- energy_daily_data %>%
  filter(point_of_delivery_specific_location == "MID-COLUMBIA (MID-C)") %>%
  group_by(customer_company_name) %>%
  summarise(expense = sum(total_transaction_charge, na.rm = TRUE)) %>%
  arrange(desc(expense))

# Create a new data frame for the top 5 customers and others
top_customers <- ranked_customers_midc %>%
  slice(1:5) %>%
  mutate(customer_company_name = factor(customer_company_name, levels = customer_company_name))

others <- ranked_customers_midc %>%
  slice(6:n()) %>%
  summarise(customer_company_name = "Others",
            expense = sum(expense))

# Combine the top 5 customers and others into one data frame
combined_data <- bind_rows(top_customers, others)

# Plot the pie chart
ggplot(combined_data, aes(x = "", y = expense, fill = customer_company_name)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Top 5 Customers in Mid-C by Expense",
    fill = "Customer"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank()
  )

print(ranked_customers_midc)
rm(combined_data, others, ranked_customers_midc, top_customers)
```

The top 5 energy buyers in Mid-C in terms of expense are:

1. TransAlta Energy Marketing (U.S.) Inc. -- \$2394861000  
2. Puget Sound Energy (PSE) -- \$1004530000  
3. Powerex Corp. -- \$993906300  
4. PacifiCorp -- \$973534400  
5. Shell Energy -- \$912868700

2 Companies purchased energy and spent more than \$1000000000 in Mid-C.  
48 Companies purchased energy and spent more than \$100000000 and less than \$1000000000 in Mid-C.  
152 Companies purchased energy and spent more than \$10000000 and less than \$100000000 in Mid-C.  
184 Companies purchased energy and spent more than \$1000000 and less than \$10000000 in Mid-C.  
132 Companies purchased energy and spent more than \$100000 and less than \$1000000 in Mid-C.  
82 Companies purchased energy and spent more than \$10000 and less than \$100000 in Mid-C.  
94 Companies purchased energy and spend less than \$10000 in Mid-C.  

Only Arlington Wind Power Project is not from California in the top 10 spender. Arlington locates in Oregon.

No.1 and No.2 switch places, NO.3 and NO.4 switch places when we count in terms of expense rather than total transaction_quantity. This means that TransAlta bought cheaper energy than Powerex and PSE bought cheaper energy than PacifiCorp. 

From the pie chart, we can see the rough proportion of money they spend on energy in the market. TransAlta is the clear dominating company. Its expense is about 11% of the whole Mid-C market. The rest of the top five contributes around 4-5% each. The proportion of others here is around 70%, which is larger than the one in COB, due to more companies that participating energy trading in Mid-C.

Seattle City Light spent \$215938682. Total expense is 533 times more than the total expense in COB. \$215938682 is 9% of the expense of the Powerex Corp. in Mid-C. We have an net income of 505864700 - 215938682 = \$289926018 in the last 10 years participating in energy transaction in Mid-C, 3.2 times the net income in COB. (126041100 + 28475090 + 24226600 + 16921260 + 10155920 + 7355836 + 2570039 + 195486.8 - 2650, from 9 different names)

We purchased 313 times more energy via Mid-C than COB, and spent 533 times more money on buying energy via Mid-C than COB. Therefore, the energy we bought from COB was on average cheaper.

We have gone through all the descriptive statistics of energy_daily_data. Let's continue on providing the descriptive statistics of energy_hourly_data. But first we need to free up some memory by removing energy_daily_data.

```{r echo=FALSE}
# Free up Memory
rm(energy_daily_data)
```

# Energy -- Hourly
## Dataset

```{r echo=FALSE}
import_energy_hourly <- function() {
  
  # Expected to have more rows than energy_daily_data
  energy_hourly_data <- data.table::fread("Final_Data_Files/final_energy_transactions_hourly.csv")
  
# Convert datatype of transaction_begin_date, transaction_end_date, and trade_date to POSIXct or date from char or int
  energy_hourly_data[, transaction_begin_date := as.POSIXct(transaction_begin_date, format="%Y/%m/%d %H:%M")]
  energy_hourly_data[, transaction_end_date := as.POSIXct(transaction_end_date, format="%Y/%m/%d %H:%M")]
  energy_hourly_data[, trade_date := lubridate::ymd(trade_date)]
  
  # Fixed unmatching cases in the increment_name column
  # H and h should be one group, D and d should be one group, so are M and m
  energy_hourly_data[, increment_name := gsub("^d$", "D", increment_name)]
  energy_hourly_data[, increment_name := gsub("^h$", "H", increment_name)]
  energy_hourly_data[, increment_name := gsub("^m$", "M", increment_name)]
  
  # Fixed unmatching cases in the point_of_delivery_specific_location column
  # There should only be two acceptable hubs: Mid-C and COB
  energy_hourly_data <- energy_hourly_data %>%
  mutate(point_of_delivery_specific_location = str_to_upper(point_of_delivery_specific_location))
  
  # Now, let's filter out the outliers
  # Definition of outliers: when price is lower than -$20 or higher than $2000
  # These data are likely incorrectly filed by the companies, so I decided to not include them in the study (it could also be due to accidents or extreme weather, but $2000/MWh is enough to cover them)
  energy_hourly_data <- energy_hourly_data %>% filter(price >= -20 & price <= 2000)
  
  # Also, non-positive transaction_quantity should not exist in the dataset as they are a result of wrong filing by companies. Only selling transactions should be filed in EQR
  energy_hourly_data <- energy_hourly_data %>% filter(transaction_quantity > 0)
  
  # We also need remove transactions with price = $0/MWh and transaction_quantity > 416 MWh, these transactions are quite likely a result of incorrect or questionable filling
  # Derived 416 by dividing 10000 by 24, the number of hours in a day
  # Unlikely that someone sold large amount of free energy in an hour
  # Doesn't matter if the filing is actually true, these data will skew the data and mess up plots
  energy_hourly_data <- energy_hourly_data %>% filter(!(price == 0 & transaction_quantity > 416))

  # We will filter out transaction with transaction_quantity > 50000 MWh
  # There are 7 such transactions
  # All 7 of them are sold by Morgan Stanley to PUD 2 of Grant County
  # All 7 transactions have a one hour duration. The transaction_quantity is too gigantic in such a short period of time
  energy_hourly_data <- energy_hourly_data %>% filter(transaction_quantity <= 50000)
  
  # Assign to the global environment
  assign("energy_hourly_data", energy_hourly_data, envir = .GlobalEnv)
}
```

```{r echo=FALSE}
import_energy_hourly()
```

Now energy_hourly_data is all set. Lets start crunching some descriptive statistics on energy_hourly_data.

## Descriptive Statistics

Here I will provide descriptive statistics of energy_hourly_data. min, Q1, median (Q2), Q3, max, mean, standard deviation (sd), interquartile range (iqr) of transaction_quantity, price, total_transaction_charge will be calculated and shown. The unit of price is $/MWh and unit of quantity is MWh. Remember, all the descriptive statistics below are measured per hour. So if a transaction has a longer hour_duration, it has more impact on the mean of transaction_quantity and total_transaction_charge.

### Subgroups -- increment_peaking_name

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by increment_peaking_name
unique_transaction_count <- energy_hourly_data %>%
  group_by(increment_peaking_name) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = increment_peaking_name, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by Increment Peaking Name",
    x = "Increment Peaking Name",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

29% more transactions are conducted during peak hours than off-peak hours, which makes sense since energy demand in peak hours is higher.

```{r echo = FALSE}
energy_hourly_data %>%
  group_by(increment_peaking_name) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity),
    q1_transaction_quantity = quantile(transaction_quantity, 0.25),
    median_transaction_quantity = median(transaction_quantity),
    q3_transaction_quantity = quantile(transaction_quantity, 0.75),
    max_transaction_quantity = max(transaction_quantity),
    mean_transaction_quantity = mean(transaction_quantity),
    sd_transaction_quantity = sd(transaction_quantity),
    iqr_transaction_quantity = IQR(transaction_quantity)
  ) %>%
  pivot_longer(
    cols = -increment_peaking_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(increment_peaking_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_hourly_data %>% filter(transaction_quantity <= 50)

ggplot(processed_data, aes(x = increment_peaking_name, y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Increment Peaking Name",
    x = "Increment Peaking Name",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

``` {r echo = FALSE}
# To make the violin plot look more comprehensible
processed_data <- energy_hourly_data %>% 
  filter(increment_peaking_name == 'FP' | increment_peaking_name == 'P' | increment_peaking_name == 'OP') %>%
  filter(transaction_quantity <= 200)

ggplot(processed_data, aes(x = increment_peaking_name, y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Increment Peaking Name",
    x = "Increment Peaking Name",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_hourly_data %>%
  group_by(increment_peaking_name) %>%
  summarise(
    min_price = min(price),
    q1_price = quantile(price, 0.25),
    median_price = median(price),
    q3_price = quantile(price, 0.75),
    max_price = max(price),
    mean_price = mean(price),
    sd_price = sd(price),
    iqr_price = IQR(price)
  ) %>%
  pivot_longer(
    cols = -increment_peaking_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(increment_peaking_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_hourly_data %>% 
  filter(price <= 150)

ggplot(processed_data, aes(x = increment_peaking_name, y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Increment Peaking Name",
    x = "Increment Peaking Name",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

```{r echo = FALSE}
energy_hourly_data %>%
  group_by(increment_peaking_name) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge),
    q1_total_transaction_charge = quantile(total_transaction_charge, 0.25),
    median_total_transaction_charge = median(total_transaction_charge),
    q3_total_transaction_charge = quantile(total_transaction_charge, 0.75),
    max_total_transaction_charge = max(total_transaction_charge),
    mean_total_transaction_charge = mean(total_transaction_charge),
    sd_total_transaction_charge = sd(total_transaction_charge),
    iqr_total_transaction_charge = IQR(total_transaction_charge)
  ) %>%
  pivot_longer(
    cols = -increment_peaking_name,
    names_to = c("stat", "variable"),
    names_pattern = "(min|q1|median|q3|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(increment_peaking_name, variable)

# To make the violin plot look more comprehensible
processed_data <- energy_hourly_data %>% 
  filter(total_transaction_charge <= 1000 & total_transaction_charge >= -200)

ggplot(processed_data, aes(x = increment_peaking_name, y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Increment Peaking Name",
    x = "Increment Peaking Name",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

The transaction quantity of N/A transactions are super small on average. Most full period transactions are also smaller than peak or off-peak transactions in terms of transaction quantity. Q3 and median are good evidence. Peak and off-peak transactions have very similar mean and median transaction_quantity, with peak transactions having a slightly larger transaction_quantity. I plotted two violin plots, one that includes N/A transactions, and one doesn't. In the first violin plot, N/A transactions almost entirely reside at the bottom part of the plot, so it makes the plot unreadable for other groups. In the second violin plot, we can see that full period transactions have bottom heavy transaction quantity distribution. Off-peak transactions are concentrated at some specific numbers, namely 25 and 50. Peak transactions are even more concentrated at those values.

Price behaves very logically here. Peak transactions are more expensive than full period transactions, and off-peak transactions are the cheapest (ignoring N/A transactions). Both mean and median price follow the same order. However, N/A transactions are weird, since the majority of transactions are free (median = \$0/MWh). In the violin plot of price, N/A is centered around \$0/MWh, with a little second peak at \$50/MWh. Full period, off-peak, and peak transactions have quite similar distribution. The little difference is that transactions with near-zero price are the most common in full period group and the least common in the peak hour group. The majority of transactions are in the range \$15/MWh to \$50/MWh.

Peak transactions have the highest total_transaction_charge in general in terms of mean and median, due to the highest average price. Full period transactions have a way lower median total_transaction_charge when compared to P or OP transactions, which makes sense since FP transactions have a low median transaction_quantity. However, FP transactions have a higher q3 and mean total_transaction_charge than OP transactions, which could be due to the higher mean total_transaction_charge and price. In the violin plot of total transaction charge, we can see that N/A is basically mostly at \$0. Full period transactions have a right-skewed distribution of total transaction charge. Off-peak and peak transactions both resembles a uniform distribution. However, it is more common to have off-peak transactions with total transaction charge below \$400, whereas it is more common to have peak transactions with total transaction charge above \$400.

### Subgroups -- transaction_begin_date

We have already analyze how transaction_begin_date affects the transaction_quantity, price, and total_transaction_charge, by grouping transactions according to their year, quarter, month, day of the week, and day of the month of the transaction_begin_date. We still haven't consider time because our energy_daily_data dataset divided transaction into days, not something more detailed like hour.

#### Transaction_begin_date --- Hour

```{r echo=FALSE}
# Calculate unique count of transaction_unique_id grouped by type_of_rate
unique_transaction_count <- energy_hourly_data %>%
  mutate(transaction_begin_hour = hour(transaction_begin_date)) %>%  # Extract Month from transaction_begin_date
  filter(!is.na(transaction_begin_hour)) %>%  # Filter out NA Hours
  group_by(transaction_begin_hour) %>%
  summarise(unique_transaction_count = n_distinct(transaction_unique_id))

# Print the result
print(unique_transaction_count)

# Plot the bar chart
ggplot(unique_transaction_count, aes(x = transaction_begin_hour, y = unique_transaction_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Number of Transactions by hour",
    x = "Hour",
    y = "Unique Transaction Count"
  ) +
  theme_minimal()

rm(unique_transaction_count)
```

There are more transactions that during HE6 to HE22 than the rest. This makes sense since HE6 to HE22 is considered peak hours, and the rest is off-peak hours. There are 12.8% fewer transactions in off-peak hours, compared to peak hours.

``` {r echo=FALSE, fig.width = 9, fig.height = 4}
processed_data <- energy_hourly_data %>%
  # Extract hour from transaction_begin_date
  mutate(transaction_begin_hour = hour(transaction_begin_date)) %>%  
  filter(!is.na(transaction_begin_hour)) %>%  # Filter out NA Hours
  group_by(transaction_begin_hour) %>%
  summarise(
    min_transaction_quantity = min(transaction_quantity, na.rm = TRUE),
    median_transaction_quantity = median(transaction_quantity, na.rm = TRUE),
    max_transaction_quantity = max(transaction_quantity, na.rm = TRUE),
    mean_transaction_quantity = mean(transaction_quantity, na.rm = TRUE),
    sd_transaction_quantity = sd(transaction_quantity, na.rm = TRUE),
    iqr_transaction_quantity = IQR(transaction_quantity, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_hour,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_hour, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_hour, y = median, color = "Median transaction_quantity")) +
  geom_point(aes(x = transaction_begin_hour, y = median, color = "Median transaction_quantity")) +
  geom_line(aes(x = transaction_begin_hour, y = mean, color = "Mean transaction_quantity")) +
  geom_point(aes(x = transaction_begin_hour, y = mean, color = "Mean transaction_quantity")) +
  geom_line(aes(x = transaction_begin_hour, y = iqr, color = "IQR transaction_quantity")) +
  geom_point(aes(x = transaction_begin_hour, y = iqr, color = "IQR transaction_quantity")) +
  labs(
    title = "Transaction Quantity by Hour",
    x = "Hour of the Day",
    y = "Transaction Quantity",
    color = "Statistic"
  ) +
  scale_x_continuous(breaks = 0:23) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE, fig.width = 10, fig.height = 3}
# To make the violin plot look more comprehensible
processed_data <- energy_hourly_data %>%
  filter(!is.na(hour(transaction_begin_date))) %>%
  filter(transaction_quantity <= 200)

ggplot(processed_data, aes(x = as.factor(hour(transaction_begin_date)), y = transaction_quantity)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Transaction Quantity by Hour",
    x = "Hour of the Day",
    y = "Transaction Quantity"
  ) +
  theme_minimal()

rm(processed_data)
```

``` {r echo=FALSE, fig.width = 9, fig.height = 4}
processed_data <- energy_hourly_data %>%
  # Extract Hour from transaction_begin_date
  mutate(transaction_begin_hour = hour(transaction_begin_date)) %>%  
  filter(!is.na(transaction_begin_hour)) %>%  # Filter out NA Hours
  group_by(transaction_begin_hour) %>%
  summarise(
    min_price = min(price, na.rm = TRUE),
    median_price = median(price, na.rm = TRUE),
    max_price = max(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
    sd_price = sd(price, na.rm = TRUE),
    iqr_price = IQR(price, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_hour,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_hour, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_hour, y = median, color = "Median price")) +
  geom_point(aes(x = transaction_begin_hour, y = median, color = "Median price")) +
  geom_line(aes(x = transaction_begin_hour, y = mean, color = "Mean price")) +
  geom_point(aes(x = transaction_begin_hour, y = mean, color = "Mean price")) +
  geom_line(aes(x = transaction_begin_hour, y = iqr, color = "IQR price")) +
  geom_point(aes(x = transaction_begin_hour, y = iqr, color = "IQR price")) +
  labs(
    title = "Price by Hour",
    x = "Hour of the Day",
    y = "Price",
    color = "Statistic"
  ) +
  scale_x_continuous(breaks = 0:23) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE, fig.width = 10, fig.height = 3}
processed_data <- energy_hourly_data %>%
  filter(!is.na(hour(transaction_begin_date))) %>%
  filter(price <= 250)

ggplot(processed_data, aes(x = as.factor(hour(transaction_begin_date)), y = price)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Price by Hour",
    x = "Hour of the Day",
    y = "Price"
  ) +
  theme_minimal()

rm(processed_data)
```

``` {r echo=FALSE, fig.width = 9, fig.height = 3.5}
processed_data <- energy_hourly_data %>%
  # Extract Hour from transaction_begin_date
  mutate(transaction_begin_hour = hour(transaction_begin_date)) %>%  
  filter(!is.na(transaction_begin_hour)) %>%  # Filter out NA Hours
  group_by(transaction_begin_hour) %>%
  summarise(
    min_total_transaction_charge = min(total_transaction_charge, na.rm = TRUE),
    median_total_transaction_charge = median(total_transaction_charge, na.rm = TRUE),
    max_total_transaction_charge = max(total_transaction_charge, na.rm = TRUE),
    mean_total_transaction_charge = mean(total_transaction_charge, na.rm = TRUE),
    sd_total_transaction_charge = sd(total_transaction_charge, na.rm = TRUE),
    iqr_total_transaction_charge = IQR(total_transaction_charge, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -transaction_begin_hour,
    names_to = c("stat", "variable"),
    names_pattern = "(min|median|max|mean|sd|iqr)_(.*)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  arrange(transaction_begin_hour, variable)

print(processed_data)

# Plot the line chart
ggplot(processed_data) +
  geom_line(aes(x = transaction_begin_hour, y = median, color = "Median total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_hour, y = median, color = "Median total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_hour, y = mean, color = "Mean total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_hour, y = mean, color = "Mean total_transaction_charge")) +
  geom_line(aes(x = transaction_begin_hour, y = iqr, color = "IQR total_transaction_charge")) +
  geom_point(aes(x = transaction_begin_hour, y = iqr, color = "IQR total_transaction_charge")) +
  labs(
    title = "Total Transaction Charge by Hour",
    x = "Hour of the Day",
    y = "Total Transaction Charge",
    color = "Statistic"
  ) +
  scale_x_continuous(breaks = 0:23) +
  ylim(0, NA) +  # Set y-axis to start at 0
  theme_minimal()

rm(processed_data)
```

```{r echo=FALSE, fig.width = 10, fig.height = 3}
# To make the violin plot look more comprehensible
processed_data <- energy_hourly_data %>%
  filter(!is.na(hour(transaction_begin_date))) %>%
  filter(total_transaction_charge <= 1500 & total_transaction_charge >= -200)

ggplot(processed_data, aes(x = as.factor(hour(transaction_begin_date)), y = total_transaction_charge)) +
  geom_violin(trim = FALSE, fill = "skyblue", color = "firebrick") +  # Violin plot
  labs(
    title = "Distribution of Total Transaction Charge by Hour",
    x = "Hour of the Day",
    y = "Total Transaction Charge"
  ) +
  theme_minimal()

rm(processed_data)
```

Both mean and median shows that transaction_quantity is lower during 00:00 to 05:59, which makes sense since it is probably considered off peak hours. Very few people are working so there is not much demand for energy. The reason transaction_quantity isn't a lot lower (median only about 20% lower) is that transactions that are longer than a day cover these low energy usage hours. When dividing a transaction into many rows by hour, I divided transaction_quantity equally. In the violin plot of transaction_quantity, the distribution of different hours look highly similar, except that it seems like 25 MWh is a tiny bit more common during HE6 to HE23.

The graph looks very similar to the transaction_quantity one, except that the median and mean price are not only the lower during 00:00 to 05:59, but also during 22:00 to 23:59. During off-peak hours, energy demand is significantly lower and drives down the energy transaction price. In the violin plot of price, we can see that there are more transactions with a price lower than \$20/MWh during off-peak hours (thicker bottom). 

Since both price and transaction_quantity is the highest from 06:00 to 21:59, the total_transaction_charge is also the highest during that time, with practically no fluctuation at all if we consider the median. Total_transaction_charge is the lowest from 00:00 to 05:59 because both price and transaction_quantity is the lowest during that time. Total_transaction_charge is to some degree higher from 22:00 to 23:59 than 00:00 to 05:59 due to the higher transaction_quantity. From the violin plot of total_transaction_charge, it is evident that the off-peak hours have a more right-skewed distribution than peak hours.

## Basic Statistics Summary (TLDR)

** The definition of the three metrics

Total Transaction Charge = Transaction Quantity * Price
Transaction Quantity = the quantity of product in a transaction
Price = the price charges for the energy per MWh

** Subgroup  = type_of_rate

Most transactions (86.4%) have either electric index or fixed type_of_rate.

Transactions of type_of_rate = formula has the highest mean and median transaction_quantity, price, and total_transaction_charge. The distribution of transaction_quantity is the most uniform out of the four groups, and it also has a clear bimodal price distribution (peak at around \$40/MWh and \$95/MWh).

Most type of rate = rto/iso transactions are small transactions and cheap transactions. Type of rate rto/iso has the smallest mean and median total transaction charge.

Transaction_quantity of type of rate = electric index are also mostly small and cheap. 

A lot of type_of_rate = fixed transactions are a bit bigger than rto/iso and electric index transactions. Fixed transactions are in general the cheapest. There are a significant number of transactions with a near-zero price. Total transcation charge has a bimodal distribution (peak close to \$0 and close to \$1000)

** Subgroup = term_name

Transactions are comprised of 24.4% LT transactions and 75.6% LT transactions.

Short-term transactions are more extreme in terms of price. Long-term transactions are more diverse in terms of price.

Price of short-term transaction are generally lower than long term transactions. Both mean (39 vs 50) and median (29 vs 36) showed that.

LT transactions have as higher mean and median total_transaction_charge than ST transactions.

Price influenced total_transaction_charge more than transaction_quantity.

** Subgroup = class_name

The vast majority (92%) of transactions are firm transactions.

Transactions classed as firm have the most extreme min and max for all three metrics, except for max transaction_quantity. Firm transactions are mostly cheap and small.

Transactions classsd as non-firm has very high sd of total_transaction_charge and total_quantity. They have a higher mean and median transasction_quantity than firm transactions. Price is the most evenly spread out from \$0/MWh to \$150/MWh across four groups.

Transactions classed as N/A are the smallest in terms of transaction_quantity, but the highest among four groups in terms of price. The price distribution is bimodal, peaking at \$25/MWh and \$50/MWh.

Transactions classed as UP have the highest median, mean and iqr for total_transaction_charge. There are significant number of transactions that are large and/or expensive. This is due to transaction_quantity spreading very evenly from \$0/MWh to \$400/MWh, making the UP transactions the least homogeneous class.

** subgroup = increment_name

62% of transactions have increment_name D and M, followed by Y, H, and 5.

Transactions with increment_name 5 and 15 have a way lower transaction_quantity than the rest. Transactions with increment_name 5 have a way higher price than the rest. The transactions with increment_name 15 has a similar mean and median price as the rest.

Transaction quantity of increment_name D, H, M, W, or Y are highly concentrated near 25 and 50 MWh. With the exception of Y, they have a lower price in general.

Long term transactions (increment_name Y) have a higher price than others (excluding than hyper short 5 minutes transactions). I believe it is due to inflation expection.

Transaction quantity of increment_name N/A has a very high mean and median transaction_quantity, and quite a low price.

** Subgroup = transaction_begin_date, year

Energy Trading is 42.1% more active since 2022 than before 2022 (ignoring incomplete 2024 data).

The mean transaction_quantity hover around 126 to 160 MWh from 2014 to 2020.  Then, it went down to a decade low point at 93 MWh in 2022 and recovered back to around 120 MWh since 2023.

There is an overall downward trend of total transaction_quantity, although it seems like the rends has been slightly reversed since 2020.

The mean and median price hovered around \$20/MWh to \$30/MWh before 2021, bar 2014. Price rose tremendously since 2021, and violin plots also show price unstability. The 2021-2023 energy crisis and policies to combat climate change are likely the reasons.

Total_transaction_charge also rose together with price.

** Subgroup = transaction_begin_date, quarter

Number of transactions in quarters ranked: 3 > 4 > 2 > 1. On average, the number of transactions in Q3 is 21.4% higher than the number in Q1.

Transaction quantity is the highest in Q2 (Median = 33 MWh), lowest in Q3 and Q4 (Median = 30 MWh). 

Pacific Northwest relies heavily on hydroelectric power. During Q2, snowmelt from the mountains significantly increase water flows, so more energy is generated. During Q3 and Q4, not much snow is melt, so water flow is the lowest and less energy is generated. Also, due to energy demand for warming, they are less energy surplus in Q4 for trading purposes.

Price is the highest in Q3 (Median = \$34.6/MWh), lowest in Q2 (Median = \$20/MWh).

Q3 is the peak energy demand period. Cooling demand is the highest in Q3, and snowmelt slows down in Q3. Higher demand and lower supply pushes the price up.

In Q2, weather is mild and calm, and snowmelt increases river flow. Lower demand and higher supply pulls down the price.

The distribution of total_transaction_charge is almost the same for all four quarters.

** Subgroup = transaction_begin_date, year, quarter

Number of transactions is the lowest in 2021-Q1 (64076), and highest in 2022 Q1 (142074).

Mean transaction_quantity peaks in 2018 Q2 at 191 MWh. Price rose sharply in 2022 Q3. Most likely because of lower gas supply worldwide due to the Russo-Ukrainian war, and demand recovery after covid lockdown.

Total transaction charge was very stable before 2022 Q3 (median). Total_transaction_charge is largely influenced by price, not as much by transaction quantity.

** Subgroup = transaction_begin_date, month

Number of transactions usually peaks in August, and hits the bottom in February. On average, there are 29.1% more transactions at the peak month than the bottom month.

Median and mean transaction quantity differ. Mean transaction quantity is the highest in May, while median is highest in February. Mean transaction quantity is the lowest in August, while median is the lowest in January.  The most common price we see are near-zero, around 25 MWh, around 50 MWh, around 100 MWh, and around 400 MWh.

Price is the lowest from March to June. Price peaks in August and December.

The ups and downs are of total transaction quantity is quite similar to those of price.

** Subgroup = transaction_begin_date, day of the week

Number of transactions on Sunday is 14.6% lower than the rest of the week on average.

Sunday has the lowest transaction quantity (median around 23.5% lower than the rest of the week), price (median around 17% lower than the rest of the week), and total transaction charge (median around 25.7% lower than normal) in general.

It is because Sunday is off peak hours and lots of business do not operate at the full level on Sunday, decreasing energy demand.

** Subgroup = transaction_begin_date, day of the month

The number of transactions is basically the same every day of the month, except 29, 30, 31.

Median and IQR of all three metrics are mostly the same everyday. The little fluctuation could be random noises.

The interesting part is mean price. By eye test, it seems like the first half of a month has a higher mean price than the second half.

Since both halves has a very similar right-skewed distribution, I decided to conduct a hypothesis testing with the Mann-Whitney U Test. The result verified the eye test.

The reason causing the difference is extreme weather. I found five incidences where extreme weather caused the energy price to skyrocket. Four out of five of them were in the first half, hence the higher price.

Another interesting finding is that all five incidences happened post-2018. It seems like climate change is hitting us at a faster rate.

** Subgroup = point_of_delivery_specific_location

Mid-Columbia (Mid-C) has 5.4 times more energy transactions than California Oregon Border (COB) [1835999 vs 339984].

Median of transaction_quantity in Mid-C is half of that in COB (25 vs 50 MWh). Mean is much closer (138 vs 159).

Transaction_quantity in Mid-C is way more concentrated in a few specific values.

Price is almost the same in both hubs (Median \$29/MWh in Mid-C vs \$31.7/MWh in COB, Mean \$40.2/MWh vs Median \$41.3/MWh). Total transaction charge is a bit higher in COB (Median \$1125 vs \$1478).

47 and 72 companies sold energy via COB and Mid-C respectively. At most 317 and 694 companies purchased energy via COB and Mid-C respectively (the number is an overestimation, some buyers are filed with different names). Mid-C has a larger market and customer base.

Top 5 energy sellers quantity wise in COB are Avangrid Renewables, Bonneville Power Administration (BPA), Shell, Iberdrola Renewables, and PacifiCorp. Seattle City Light ranks 14/47, sold 2323380 MWh over than last ten years. 

Top 5 energy sellers revenue wise in COB have same big 5. Seattle City Light ranks 15/47, earned \$90790870 over the last ten years.

Top 5 energy buyers quantity wise in COB are Sacramento Municipal Utility District (SMUD), California Independent Systems Operation CORP DBA CALIF (CAL DBA), Modesto Irrigation District (MID), Southern California Edison (SCE), and Turlock Irrigation District (TID). 9 out of the top 10 sellers are from California, and the remaining one used to be. Seattle City Light bought 16252.5 MWh of energy during the past ten years, not an important buyer in COB.

Top 5 energy buyers expense wise in COB are SMUD, Cal DBA, MID, Pacific Gas and Electric (PG&E), and SCE. Only Arlington Wind Power Project and Exelon are not from California in the top 10. Seattle City Light spent Seattle City Light spent $ 405288.6, so again an unimportant buyer in COB.

Top 5 energy sellers quantity wise in Mid-C are Shell, TransAlta Centralia, BPA, Public Utility District No.1 of Chelan County (PUD Chelan), and TransAlta Energy Marketing.

Seattle City Light ranks 11/72, sold close to 30% of the total amount of the no.1 company (67032560 vs 19419080 MWh), 8.4 times of the amount we sold via COB.

Top 5 energy sellers revenue wise in Mid-C are TransAlta Centralia, Shell, PUD Chelan, TransAlta Energy Marketing, and ConocoPhillips.

Seattle City Light ranks 15/72, about 22% of revenue earned by the no.1 company (\$2348233000 vs \$505864700).

We sold 8.4 times more energy via Mid-C, but only 5.6 times more revenue than COB. More efficient at generating revenue in COB, more production in Mid-C.

Top 5 energy buyers quantity wise in Mid-C are TransAlta Energy Marketing, Powerex, Shell, Puget Sound Energy (PSE), and PacifiCorp.

Seattle City Light purchased 5091231 MWh, 313 times more than what we purchased via COB.

Top 5 energy buyers expense wise in Mid-C are TransAlta Energy Marketing, PSE, Powerex, PacifiCorp, and Shell.

Seattle City Light spent \$ 215938682 on energy trade in Mid-C, 533 times the amount we spent in COB. The energy we bought from COB was on average cheaper.

Our net income from participating energy trade in COB is \$90385581.  Our net income from participating energy trade in COB is \$289926018.

** Subgroups -- increment_peaking_name

The number of transactions has such a ratio when divided by increment_peaking_name. 1.0 FP : 2.3 OP : 3.0 P. We can ignore N/A transactions since there are so few of them. 

On average, N/A transactions have a very low transaction_quantity and price.

Most full period transactions have a lower transaction_quantity than peak and off-peak transactions.

Off-peak transactions are the cheapest, peak transactions are the most expensive (ignoring N/A transactions).

Peak transactions have the highest total_transaction_charge due to higher price. Full period transactions have the lowest median total_transaction_charge, bar N/A transactions, due to lower transaction_quantity. Off-peak transactions have the lowest mean total_transaction_charge, due to cheaper price.

** Subgroups -- transaction_begin_date, hour

There are 12.8% fewer transactions in off-peak hours, compared to peak hours.

Transaction_quantity is lower during 00:00 to 05:59, and higher during 06:00 to 23:59.

Price is higher during 06:00 to 21:59 (peak hours), and lower during 00:00 to 05:59 and 22:00 to 23:59 (off-peak hours).

Total_transaction_charge is the highest during peak hours, and the lowest during 00:00 to 05:59. It is in the middle during 22:00 to 23:59.

The distribution of total_transaction_charge and price of off-peak hours is more bottom-heavy than peak hours.

Now we understand the energy transaction quantity, price, and total transaction charge comprehensively. The next step is to do a correlation study between quantity, price, and ICE daily index. We will continue to use energy_hourly_data, because ICE daily index has two price. One is for peak hours, another for off-peak hours.

# Energy and ICE Daily Index
## Dataset

```{r echo=FALSE}
# I used fread() because it is faster than read.csv() and read_csv()
ICE_data_midc <- data.table::fread("Final_Data_Files/ICE_data_midc.csv")
ICE_data_cob <- data.table::fread("Final_Data_Files/ICE_data_cob.csv")
```

Read some rows to test the usability of the dataset.

```{r echo=FALSE}
head(ICE_data_midc, n = 5)
head(ICE_data_cob, n = 5)
```

We need to transform the ICE_data_midc dataset so that it is more user-friendly. First we create a peak_name column, which determines if a row contains off-peak price or peak-price.

```{r echo=FALSE}
ICE_data_midc$Peak_Name <- ifelse(grepl("Off-Peak", ICE_data_midc$HUB_NAME), "Off-Peak", "Peak")
ICE_data_cob$Peak_Name <- ifelse(grepl("Off-Peak", ICE_data_cob$HUB_NAME), "Off-Peak", "Peak")
```

Now we unify HUB_NAME to a single value: Mid-Columbia (Mid-C).

```{r echo=FALSE}
ICE_data_midc$HUB_NAME <- 'MID-COLUMBIA (MID-C)'	
ICE_data_cob$HUB_NAME <- 'COB'
```

Next, we will merge OFF_PEAK_PRICE and PEAK_PRICE into one Price variable.

```{r echo=FALSE}
ICE_data_midc$Price <- ifelse(is.na(ICE_data_midc$OFF_PEAK_PRICE),
                              ICE_data_midc$PEAK_PRICE, ICE_data_midc$OFF_PEAK_PRICE)
ICE_data_midc = select(ICE_data_midc, -c('OFF_PEAK_PRICE', 'PEAK_PRICE'))

ICE_data_cob$Price <- ifelse(is.na(ICE_data_cob$OFF_PEAK_PRICE),
                             ICE_data_cob$PEAK_PRICE, ICE_data_cob$OFF_PEAK_PRICE)
ICE_data_cob = select(ICE_data_cob, -c('OFF_PEAK_PRICE', 'PEAK_PRICE'))
```

Then, let's rename some columns.

```{r echo=FALSE}
# Rename some Columns
ICE_data_midc <- ICE_data_midc %>% rename(
  Hub_Name = HUB_NAME,
  Price_Date = PRICE_DATE,
  Day_Of_Week = DAYOFWEEK
)

ICE_data_cob <- ICE_data_cob %>% rename(
  Hub_Name = HUB_NAME,
  Price_Date = PRICE_DATE,
  Day_Of_Week = DAYOFWEEK
)
```

I also want to change the format of Price_Date from MM/DD/YYYY to YYYY/MM/DD.

```{r echo=FALSE}
# Convert Price_Date from MM/DD/YYYY to YYYY/MM/DD
ICE_data_midc$Price_Date <- ymd(mdy(ICE_data_midc$Price_Date))
ICE_data_cob$Price_Date <- ymd(mdy(ICE_data_cob$Price_Date))
```

I realized that there are no price on some dates. My approach so solve this problem is the copy the data from the previous date.

```{r echo=FALSE}
library(timeDate)
library(zoo)

# Determine whether the input date is a NERC holiday
is_nerc_holiday <- function(date) {
  date <- as.Date(date)  # Ensure date is in Date format
  year <- as.numeric(format(date, "%Y"))
  
  # Get U.S. Federal holidays
  new_year <- as.Date(USNewYearsDay(year))
  memorial_day <- as.Date(USMemorialDay(year))
  independence_day <- as.Date(USIndependenceDay(year))
  labor_day <- as.Date(USLaborDay(year))
  thanksgiving <- as.Date(USThanksgivingDay(year))
  christmas <- as.Date(USChristmasDay(year))
  
  # List of NERC holidays
  nerc_holidays <- c(new_year, memorial_day, independence_day, labor_day, thanksgiving, christmas)
  
  # Check if the date is in the list of holidays
  return(as.Date(date) %in% as.Date(nerc_holidays))
}

# Full date sequence from 11/02/2018 to 03/31/2024
date_range <- seq(as.Date("2018-11-02"), as.Date("2024-03-31"), by = "day")

# Convert Price_Date to Date type in ICE datasets (assuming Price_Date format issue is resolved)
ICE_data_midc$Price_Date <- as.Date(ICE_data_midc$Price_Date, format = "%Y/%m/%d")
ICE_data_cob$Price_Date <- as.Date(ICE_data_cob$Price_Date, format = "%Y/%m/%d")

# Create the full sequence of dates and match with peak and off-peak data
all_dates <- expand.grid(
  Price_Date = date_range,
  Peak_Name = c("Peak", "Off-Peak")
)

# Filter for Off-Peak prices on Sundays and NERC holidays
all_dates <- all_dates %>%
  mutate(
    Day_Of_Week = weekdays(Price_Date, abbreviate = TRUE),
    is_sunday = (Day_Of_Week == "Sun"),
    is_nerc_holiday = sapply(Price_Date, is_nerc_holiday)
  ) %>%
  filter(!(Peak_Name == "Peak" & (is_sunday | is_nerc_holiday))) %>%  # Remove Peak for Sundays and NERC holidays
  select(-is_sunday, -is_nerc_holiday)

# Left join to detect missing dates for either peak or off-peak
filled_midc <- all_dates %>%
  left_join(ICE_data_midc, by = c("Price_Date", "Peak_Name")) %>% 
  select(-Day_Of_Week.y) %>% 
  rename(Day_Of_Week = Day_Of_Week.x)

# For whatever reason, some of the HUB_NAME is empty
filled_midc$Hub_Name <- 'MID-COLUMBIA (MID-C)'

filled_midc <- filled_midc %>%
  arrange(Price_Date) %>%
  group_by(Peak_Name) %>%
  mutate(
    Price = na.locf(Price)  # Use last observation carried forward
  ) %>%
  ungroup()

# Left join to detect missing dates for either peak or off-peak
filled_cob <- all_dates %>%
  left_join(ICE_data_cob, by = c("Price_Date", "Peak_Name")) %>% 
  select(-Day_Of_Week.y) %>% 
  rename(Day_Of_Week = Day_Of_Week.x)

# For whatever reason, some of the HUB_NAME is empty
filled_cob$Hub_Name <- 'COB'

filled_cob <- filled_cob %>%
  arrange(Price_Date) %>%
  group_by(Peak_Name) %>%
  mutate(
    Price = na.locf(Price)  # Use last observation carried forward
  ) %>%
  ungroup()
```

```{r echo=FALSE}
# Clean Up
ICE_data_midc <- filled_midc
ICE_data_cob <- filled_cob

rm(filled_cob, filled_midc, date_range, all_dates)
```

ICE_data_midc and ICE_data_cob contain data for all dates from 11/02/2018 to 03/31/2024 now.

Since we will need to merge the ICE datasets with energy_hourly_data based on dates and hours, we will need to duplicate the rows of each days in ICE datasets. There should be 24 rows for each day. Remember, Sundays and NERC holidays are considered off-peak the whole day. For regular Monday to Saturday, only HE1 to HE6 and HE22 to HE23 are considered off-peak.

```{r echo=FALSE}
# Function to expand rows based on Peak_Name and if it's a NERC holiday or a Sunday
expand_rows <- function(df) {
  df %>%
    rowwise() %>%
    mutate(expansion = case_when(
      Day_Of_Week == "Sun" | is_nerc_holiday(Price_Date) ~ list(0:23),  # Duplicate 24 times for Sundays or NERC holidays
      Peak_Name == "Off-Peak" & Day_Of_Week != "Sun" ~ list(c(0:5, 22:23)),  # 8 times for Off-Peak (00-05, 22-23)
      Peak_Name == "Peak" & Day_Of_Week != "Sun" ~ list(6:21)  # 16 times for Peak (06-21)
    )) %>%
    unnest(expansion) %>%
    mutate(
      # Generate proper POSIXct timestamps for each expanded row, specifying the time zone to handle DST correctly
      Price_Date = as.POSIXct(
        paste(Price_Date, sprintf("%02d:00:00", expansion)),
        format = "%Y-%m-%d %H:%M:%S",
        tz = "US/Pacific"
      )
    ) %>%
    select(-expansion)  # Remove helper column
}

# Apply the function to expand rows
ICE_data_midc <- expand_rows(ICE_data_midc)
ICE_data_cob <- expand_rows(ICE_data_cob)
```

Double check if any cell is empty in ICE_data_midc and ICE_data_cob.

```{r}
ICE_data_cob %>%
  filter(if_any(everything(), is.na))

ICE_data_midc %>%
  filter(if_any(everything(), is.na))
```

There are 6 rows with empty Price_Date. Let's find out what Price_Date are missing.

```{r}
# Generate the full sequence of date-hour combinations using seq.timeDate()
full_date_hours <- seq.POSIXt(from = as.POSIXct("2018-11-02 00:00:00"),
                                to = as.POSIXct("2024-03-31 23:00:00"), by = "hour")
```

```{r}
# Find missing dates in each dataset by comparing to the full sequence
missing_dates_midc <- setdiff(as.vector(full_date_hours), as.vector(ICE_data_midc$Price_Date))
missing_dates_cob <- setdiff(as.vector(full_date_hours), as.vector(ICE_data_cob$Price_Date))

missing_dates_midc <- format(as.POSIXct(missing_dates_midc), "%Y-%m-%d %H:%M:%S")
missing_dates_cob <- format(as.POSIXct(missing_dates_cob), "%Y-%m-%d %H:%M:%S")

print(missing_dates_midc)
print(missing_dates_cob)
```

There are six missing Price_Date. It seems like they are all 01:00:00 in the first Sunday of November. The missing Price_Date is caused by the changing the daylight saving time to standard time. We can simply filter out these missing Price_Date.

```{r}
ICE_data_midc <- ICE_data_midc %>%
  filter(!is.na(Price_Date))

ICE_data_cob <- ICE_data_cob %>%
  filter(!is.na(Price_Date))
```

We don't need minutes and seconds, so let's reformat Price_Date of both datasets.

```{r}
# Reformat Price_Date to "YYYY-MM-DD HH" format
ICE_data_cob$Price_Date <- format(as.POSIXct(ICE_data_cob$Price_Date), "%Y-%m-%d %H")
ICE_data_midc$Price_Date <- format(as.POSIXct(ICE_data_midc$Price_Date), "%Y-%m-%d %H")

# Verify the change
head(ICE_data_cob$Price_Date)
head(ICE_data_midc$Price_Date)
```

```{r}
rm(full_date_hours, missing_dates_cob, missing_dates_midc)
```


Finally, we have all the datasets ready. Let's begin to do plot some line charts, regression charts and perhaps some other graphs.

## Mean Energy Price and ICE Daily Index Analysis

```{r echo=FALSE}
# Step 1: Extract 'YYYY/MM/DD HH' from 'transaction_begin_date' and calculate daily mean price
mean_energy_price_midc <- energy_hourly_data %>%
  filter(point_of_delivery_specific_location == "MID-COLUMBIA (MID-C)") %>% 
  mutate(transaction_begin_hour = format(transaction_begin_date, "%Y-%m-%d %H")) %>%
  group_by(transaction_begin_hour) %>%
  summarise(mean_price = mean(price, na.rm = TRUE),
            median_price = median(price, na.rm = TRUE))

mean_energy_price_cob <- energy_hourly_data %>%
  filter(point_of_delivery_specific_location == "COB") %>% 
  mutate(transaction_begin_hour = format(transaction_begin_date, "%Y-%m-%d %H")) %>%
  group_by(transaction_begin_hour) %>%
  summarise(mean_price = mean(price, na.rm = TRUE),
            median_price = median(price, na.rm = TRUE))

# Step 2: Merge ICE_data_midc with daily mean prices from energy_hourly_transaction on Price_Date
merged_data_midc <- merge(ICE_data_midc, mean_energy_price_midc, by.x = "Price_Date", by.y = "transaction_begin_hour") %>%
  filter(!(is.na(Price_Date)))
merged_data_cob <- merge(ICE_data_cob, mean_energy_price_cob, by.x = "Price_Date", by.y = "transaction_begin_hour") %>%
  filter(!(is.na(Price_Date)))
```

```{r}
rm(mean_energy_price_midc, mean_energy_price_cob)

# Convert Price_Date to POSIXct for both merged datasets
merged_data_midc$Price_Date <- as.POSIXct(merged_data_midc$Price_Date, format = "%Y-%m-%d %H")
merged_data_cob$Price_Date <- as.POSIXct(merged_data_cob$Price_Date, format = "%Y-%m-%d %H")

# Step 3: Plot Scatter Plot

# Fit a linear model for Mid-C data
lm_midc <- lm(mean_price ~ Price, data = merged_data_midc)

# Extract the R-squared value
r_squared_midc <- summary(lm_midc)$r.squared
print(paste("R-squared value for Mid-C: ", r_squared_midc))

# Scatter plot with R-squared value in the title
ggplot(merged_data_midc, aes(x = Price, y = mean_price)) +
  geom_point() +  # Dots
  geom_smooth(method = "lm", se = FALSE, color = 'seagreen') +  # Best Fit Line
  labs(x = "ICE Price", y = "Mean Energy Transaction Price", 
       title = "ICE Index vs EQR Hourly Avg. Energy Price in Mid-C") +
  theme_minimal()

# Fit a linear model for COB data
lm_cob <- lm(mean_price ~ Price, data = merged_data_cob)

# Extract the R-squared value
r_squared_cob <- summary(lm_cob)$r.squared
print(paste("R-squared value for COB: ", r_squared_cob))

# Scatter plot with R-squared value in the title
ggplot(merged_data_cob, aes(x = Price, y = mean_price)) +
  geom_point() +  # Dots
  geom_smooth(method = "lm", se = FALSE, color = 'seagreen') +  # Best Fit Line
  labs(x = "ICE Price", y = "Mean Energy Transaction Price", 
       title = "ICE Index vs EQR Hourly Avg. Energy Price in COB") +
  theme_minimal()

ggplot(merged_data_midc, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "ICE Index vs EQR Hourly Avg. Energy Price in Mid-C") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

ggplot(merged_data_cob, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "ICE Index vs EQR Hourly Avg. Energy Price in COB") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(lm_cob, lm_midc, r_squared_cob, r_squared_midc)
```

From the scatter plots, we can see that there is a far stronger positive relationship between ICE index and mean energy transaction price in Mid-C than COB. From the line chart of Mid-C, we can see that the two lines go same direction. A lot of the times they look overlapped on the chart. However, the line chart of COB tells a different story. There are many times when one line surges, the other doesn't. Since the chart includes data from many days, we need to zoom into each year so we can inspect the line chart better.

```{r echo=FALSE}
merged_data_midc_201819 <- merged_data_midc %>% filter(year(Price_Date) %in% c(2018, 2019))

ggplot(merged_data_midc_201819, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_201819)

merged_data_midc_2020 <- merged_data_midc %>% filter(year(Price_Date) == 2020)

ggplot(merged_data_midc_2020, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_2020)

merged_data_midc_2021 <- merged_data_midc %>% filter(year(Price_Date) == 2021)

ggplot(merged_data_midc_2021, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_2021)

merged_data_midc_2022 <- merged_data_midc %>% filter(year(Price_Date) == 2022)

ggplot(merged_data_midc_2022, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_2022)

merged_data_midc_202324<- merged_data_midc %>% filter(year(Price_Date) %in% c(2023, 2024))

ggplot(merged_data_midc_202324, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_202324)
```

```{r echo=FALSE}
merged_data_cob_201819 <- merged_data_cob %>% filter(year(Price_Date) %in% c(2018, 2019))

ggplot(merged_data_cob_201819, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_201819)

merged_data_cob_2020 <- merged_data_cob %>% filter(year(Price_Date) == 2020)

ggplot(merged_data_cob_2020, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_2020)

merged_data_cob_2021 <- merged_data_cob %>% filter(year(Price_Date) == 2021)

ggplot(merged_data_cob_2021, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_2021)

merged_data_cob_2022 <- merged_data_cob %>% filter(year(Price_Date) == 2022)

ggplot(merged_data_cob_2022, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_2022)

merged_data_cob_202324<- merged_data_cob %>% filter(year(Price_Date) %in% c(2023, 2024))

ggplot(merged_data_cob_202324, aes(x = Price_Date)) +
  geom_line(aes(y = mean_price, color = "Mean Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Mean Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Mean Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_202324)
```

Now we can see clearly that the two prices didn't match all the time. There are times where ICE index price or mean energy transaction price shot up very sharply, but the other price didn't. It could be due to some outlier transactions, so one way to look deeper into this issue is to use median energy transaction price in COB instead.

## Median Energy Price and ICE Daily Index Analysis

```{r echo=FALSE}
# Step 1: Extract 'YYYY/MM/DD HH' from 'transaction_begin_date' and calculate daily mean price
median_energy_price_midc <- energy_hourly_data %>%
  filter(point_of_delivery_specific_location == "MID-COLUMBIA (MID-C)") %>% 
  mutate(transaction_begin_hour = format(transaction_begin_date, "%Y-%m-%d %H")) %>%
  group_by(transaction_begin_hour) %>%
  summarise(mean_price = mean(price, na.rm = TRUE),
            median_price = median(price, na.rm = TRUE))

median_energy_price_cob <- energy_hourly_data %>%
  filter(point_of_delivery_specific_location == "COB") %>% 
  mutate(transaction_begin_hour = format(transaction_begin_date, "%Y-%m-%d %H")) %>%
  group_by(transaction_begin_hour) %>%
  summarise(mean_price = mean(price, na.rm = TRUE),
            median_price = median(price, na.rm = TRUE))

# Step 2: Merge ICE_data_midc with daily mean prices from energy_hourly_transaction on Price_Date
merged_data_midc <- merge(ICE_data_midc, median_energy_price_midc, by.x = "Price_Date", by.y = "transaction_begin_hour") %>%
  filter(!(is.na(Price_Date)))
merged_data_cob <- merge(ICE_data_cob, median_energy_price_cob, by.x = "Price_Date", by.y = "transaction_begin_hour") %>%
  filter(!(is.na(Price_Date)))
```

```{r}
rm(median_energy_price_midc, median_energy_price_cob)

# Convert Price_Date to POSIXct for both merged datasets
merged_data_midc$Price_Date <- as.POSIXct(merged_data_midc$Price_Date, format = "%Y-%m-%d %H")
merged_data_cob$Price_Date <- as.POSIXct(merged_data_cob$Price_Date, format = "%Y-%m-%d %H")

# Step 3: Plot Scatter Plot

# Fit a linear model for Mid-C data
lm_midc <- lm(median_price ~ Price, data = merged_data_midc)

# Extract the R-squared value
r_squared_midc <- summary(lm_midc)$r.squared
print(paste("R-squared value for Mid-C: ", r_squared_midc))

# Scatter plot with R-squared value in the title
ggplot(merged_data_midc, aes(x = Price, y = median_price)) +
  geom_point() +  # Dots
  geom_smooth(method = "lm", se = FALSE, color = 'seagreen') +  # Best Fit Line
  labs(x = "ICE Price", y = "Median Energy Transaction Price", 
       title = "ICE Index vs EQR Hourly Median Energy Price in Mid-C") +
  theme_minimal()

# Fit a linear model for COB data
lm_cob <- lm(median_price ~ Price, data = merged_data_cob)

# Extract the R-squared value
r_squared_cob <- summary(lm_cob)$r.squared
print(paste("R-squared value for COB: ", r_squared_cob))

# Scatter plot with R-squared value in the title
ggplot(merged_data_cob, aes(x = Price, y = median_price)) +
  geom_point() +  # Dots
  geom_smooth(method = "lm", se = FALSE, color = 'seagreen') +  # Best Fit Line
  labs(x = "ICE Price", y = "Median Energy Transaction Price", 
       title = "ICE Index vs EQR Hourly Median Energy Price in COB") +
  theme_minimal()

ggplot(merged_data_midc, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "ICE Index vs EQR Hourly Median Energy Price in Mid-C") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

ggplot(merged_data_cob, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "ICE Index vs EQR Hourly Median Energy Price in COB") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(lm_cob, lm_midc, r_squared_cob, r_squared_midc)
```

From the scatter plot, we can clearly see that median energy transaction price has a weak correlation with ICE Index Price, comparing to mean energy transaction price. Regardless, I will still show the zoom in version of line charts for extra information.

```{r echo=FALSE}
merged_data_midc_201819 <- merged_data_midc %>% filter(year(Price_Date) %in% c(2018, 2019))

ggplot(merged_data_midc_201819, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_201819)

merged_data_midc_2020 <- merged_data_midc %>% filter(year(Price_Date) == 2020)

ggplot(merged_data_midc_2020, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_2020)

merged_data_midc_2021 <- merged_data_midc %>% filter(year(Price_Date) == 2021)

ggplot(merged_data_midc_2021, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_2021)

merged_data_midc_2022 <- merged_data_midc %>% filter(year(Price_Date) == 2022)

ggplot(merged_data_midc_2022, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_2022)

merged_data_midc_202324<- merged_data_midc %>% filter(year(Price_Date) %in% c(2023, 2024))

ggplot(merged_data_midc_202324, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in Mid-C") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_midc_202324)
```

```{r echo=FALSE}
merged_data_cob_201819 <- merged_data_cob %>% filter(year(Price_Date) %in% c(2018, 2019))

ggplot(merged_data_cob_201819, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_201819)

merged_data_cob_2020 <- merged_data_cob %>% filter(year(Price_Date) == 2020)

ggplot(merged_data_cob_2020, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_2020)

merged_data_cob_2021 <- merged_data_cob %>% filter(year(Price_Date) == 2021)

ggplot(merged_data_cob_2021, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_2021)

merged_data_cob_2022 <- merged_data_cob %>% filter(year(Price_Date) == 2022)

ggplot(merged_data_cob_2022, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_2022)

merged_data_cob_202324<- merged_data_cob %>% filter(year(Price_Date) %in% c(2023, 2024))

ggplot(merged_data_cob_202324, aes(x = Price_Date)) +
  geom_line(aes(y = median_price, color = "Median Energy Transaction Price")) +  # Line for mean energy price
  geom_line(aes(y = Price, color = "ICE Index Price")) +  # Line for ICE index price
  labs(x = "Date/Time", y = "Price", title = "Hourly Median Energy Transaction Price vs ICE Index Price in COB") +
  scale_color_manual("", values = c("Median Energy Transaction Price" = "cadetblue", "ICE Index Price" = "darkgoldenrod")) +
  theme_minimal() +
  theme(legend.position = "bottom")

rm(merged_data_cob_202324)
```

Clean all variables that we won't use before moving the other analysis.

```{r echo=FALSE}
rm(ICE_data_cob, ICE_data_midc, merged_data_cob, merged_data_midc, energy_hourly_data)
```

# Energy and Gas Price
## Dataset

Lets import the gas price dataset. Here gas_price refers to Washington All Grades Conventional Retail Gasoline Prices. The data source is https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=pet&s=emm_epm0u_pte_swa_dpg&f=m. I only retrieved the data from Jan 2014 to Mar 2024. I will also reload energy_daily_data.

```{r echo=FALSE}
# Import gas price dataset
gas_price_data <- data.table::fread("Final_Data_Files/gas_price.csv")

# Read some rows to test the usability of the dataset
head(gas_price_data, n = 5)
```

```{r echo=FALSE}
# Reload energy_daily_data
import_energy_daily()
```
We want the format of transaction_begin_date to be YYYY/MM.

```{r echo=FALSE}
processed_data <- energy_daily_data %>%
  mutate(transaction_begin_ym = format(transaction_begin_date, "%Y/%m")) %>% 
  filter(!is.na(transaction_begin_ym)) %>% 
  group_by(transaction_begin_ym) %>% 
  summarise(
    median_price = median(price, na.rm = TRUE),
    mean_price = mean(price, na.rm = TRUE),
  )
```

## Energy Price and Gas Price Analysis

Gas price data is from https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?f=m&n=pet&s=emm_epm0_pte_nus_dpg.

```{r echo=FALSE}
# Convert year_month columns to Date type
gas_price_data <- gas_price_data %>%
  mutate(year_month = as.Date(paste0(year_month, "/01"), format="%Y/%m/%d"))

processed_data <- processed_data %>%
  mutate(transaction_begin_ym = as.Date(paste0(transaction_begin_ym, "/01"), format="%Y/%m/%d"))

# Merge the datasets on year_month
merged_data <- merge(gas_price_data, processed_data, by.x = "year_month", by.y = "transaction_begin_ym") %>% 
  filter(!(year_month %in% c("2023/08/01", "2022/09/01", "2023/01/01", "2024/01/01", "2022/12/01")))

# Fit a linear model for mean price
lm_mean <- lm(gas_price ~ mean_price, data = merged_data)

# Extract the R-squared value
r_squared <- summary(lm_mean)$r.squared
print(paste("R-squared value: ", r_squared))

# Scatter plot with R-squared value in the title
ggplot(merged_data, aes(x = gas_price, y = mean_price)) +
  geom_point() +  # Dots
  geom_smooth(method = "lm", se = FALSE, color = 'seagreen') +  # Best Fit Line
  labs(x = "Gas Price", y = "Mean Energy Transaction Price", 
       title = "Gas Price vs EQR Monthly Avg. Energy Price") +
  theme_minimal()

# Fit a linear model for median price
lm_median <- lm(gas_price ~ median_price, data = merged_data)

# Extract the R-squared value
r_squared <- summary(lm_median)$r.squared
print(paste("R-squared value: ", r_squared))

# Scatter plot with R-squared value in the title
ggplot(merged_data, aes(x = gas_price, y = median_price)) +
  geom_point() +  # Dots
  geom_smooth(method = "lm", se = FALSE, color = 'seagreen') +  # Best Fit Line
  labs(x = "Gas Price", y = "Median Energy Transaction Price", 
       title = "Gas Price vs EQR Monthly Median Energy Price") +
  theme_minimal()

# Plot
ggplot(merged_data, aes(x = year_month)) +
  geom_line(aes(y = gas_price, color = "Gas Price")) +
  geom_line(aes(y = median_price, color = "Median Price")) +
  geom_line(aes(y = mean_price, color = "Mean Price")) +
  labs(
    title = "Gas Price, Median Price, and Mean Price Over Time",
    x = "Date (Year/Month)",
    y = "Price",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Gas Price" = "blue", "Median Price" = "green", "Mean Price" = "red")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

It seems like gas price only has a weak linear correlation with the actual mean or median energy transaction price. The dots is quite sporadic seems to have no other types of correlation either (exponential, quadratic, logarithmic). So, let's remove the some variables and move on to coal prices.

```{r echo=FALSE}
rm(lm_mean, lm_median, merged_data, processed_data, gas_price_data)
```


()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()
Priortize Energy product, after that we do ancillary.
Then try to plot regression graphs with the transaction data.
Find if any relation exists between transaction data and other data (hydro, solar, weather, gas price)
Other ideas: other regional market (CAISO), GHG regulation impact, outages, regional load/ peak load, transmission, other hubs [could they affect the trading activity in MId-C and COB? fewer transactions in 2017-2021, higher avg mwh], energy generation type by year (coal, gas, wind, hydro, etc.) [could it affect the price and quantity?], dig deeper in the biggest sellers and customers.
()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()

# Ancillary Daily

# Ancillary Hourly

# Column Definition

To make sure readers understand meaning of each column, here is the definition of the terms. Reference: https://www.ferc.gov/sites/default/files/2020-11/Data_Dictionary_V3_5_Clean.pdf

transaction_unique_id: An identifier used to desingate a record containing transformation. Char.

seller_company_name: The name of the company that is authorized to make sales. Char.

customer_company_name: The name of the purchaser. Char.

ferc_tariff_reference: The FERC tariff reference cites the document that specifies the terms and conditions under which a Seller is authorized to make transmission sales, power sales or sales of related jurisdictional services at cost-based rates or at market-based rates. If a non-public utility does not have a FERC Tariff Reference, "NPU" is the value. Char.

contract_service_agreement: Unique identifier given to each service agreement that can be used by the Seller to produce the agreement, if requested. Char.

transaction_unique_identifier: Unique reference number assigned by the Seller for each transaction. Char.

transaction_begin_date: First date and time the product is sold during the quarter. Format: YYYY/MM/DD HH:mm. Char.

transaction_end_date: Last date and time the product is sold during the quarter. Format: YYYY/MM/DD HH:mm. Char.

trade_date: The date upon which the parties made the legally binding agreement on the price. Format: YYYYMMDD. Int.

exchange_brokerage_service: BROKER -- A broker was used to consummate or effectuate the transaction. ICE -- Intercontinental exchange. NODAL -- Nodal Exchange. NYMEX -- New York Mercantile Exchange.

type_of_rate: Fixed -- A fixed charge per unit of consumption. Formula -- A calculation of a rate based upon a formula that does not contain an electic index component. Electric Index -- A calculation of a rate based upon an index or a formula that contains an electric index component. RTO/ISO -- If the price is the result of an RTO (Independent System Operators)/ISO (Independent System Operators) market or the sale is made to the RTO/ISO.

time_zone: Time zone in which the sale was made.

point_of_delivery_balancing_authority: The registered Balancing Authority abbreviatoin used in OASIS applications.

point_of_delivery_specific_location: The specific location at which the product is delivered.

class_name: F -- firm. A sale, service or product that is not interruptible for economic reasons. NF -- Non-firm. A sale for which delivery or receipt of the energy may be interupted for any reason or no reason. UP -- Unit Power Sale. Designates a dedicated sale of energy and capacity from one or more specified generation unit(s). BA -- Billing Adjustment. Designates an incremental material change to one or more transactions due to a change in settlement results. N/A is used when other class names do not apply.

term_name: LT -- long term. ST -- short term. N/A -- not applicable. Power sales transactions with durations of one year or greater are longterm. Transactions with shorter durations are short-term.

increment_name: 5 -- Five-Minute. Terms of the particular sale set for > 0 and ≤ 5 minutes. 15 -- Fifteen-Minute. Terms of particular sale set for > 5 and ≤ 15 minutes. H -- hourly. terms of the particular sale set > 15 minutes and ≤ 6 hours. D -- daily. Terms of the particular sale set for > 6 and ≤ 60 hours). Includes sales over a peak or off-peak block during a single day. W -- weekly. Terms of the particular sale set for > 60 and ≤ 168 hours. Includes sales for a full week and sales for peak and off-peak blocks over a particular week. M -- monthly. Terms of the particular sale set for set for > 168 hours and < 1 year. Includes sales for full month or multi-week sales during a given month. Y -- yearly. Terms of the particular sale set for ≥ 1 year. Includes all long-term contracts with defined pricing terms (fixed-price, formula, or index). N/A is used when other increment name does not apply.

increment_peaking_name: FP -- full period. The product was sold during peak and off-peak hours. OP -- off-peak. The product was sold during off-peak hours. HE1-6, HE23-24 on Monday to Saturday. Whole day on Sunday and NERC holidays. P -- peak. The product was sold during peak hours. HE7-22 on Monday to Saturday.

product_name: Description of product being offered.

transaction_quantity: The quantity of the product in this transaction record.

price: Actual price charged for the product per unit.

rate_units: Actual price charged for the product per unit.

standardized_quantity: For product names energy, capacity, and booked out power only. Specify the quantity in MWh if the product is energy or booked out power and specify the quantity in MW-month if the product is capacity or booked out power.

standardized_price: For product names energy, capacity, and booked out power only. Specify the price in \$/MWh if the product is energy or booked out power and specify the price in \$/MW-month if the product is capacity or booked out power. 

total_transmission_charge: Payments received for transmission services when explicitly identified.

total_transaction_charge: $\text{transaction_quantity} \times \text{price} + \text{total_transmission_charge}$.

day_duration: $\text{transaction_end_date} - \text{transaction_begin_date}$. Round up to the nearest integer. This is the original duration (in days) of the transaction. If a transaction_unique_id appears 10 times, day_duration is 10.

hour_duration: $\text{transaction_end_date} - \text{transaction_begin_date}$. Round up to the nearest integer. This is the original duration (in hours) of the transaction. If a transaction_unique_id appears 10 times, hour_duration is 10. It has taken peak and off-peak hours into account so that hourly analysis could be accurate.

